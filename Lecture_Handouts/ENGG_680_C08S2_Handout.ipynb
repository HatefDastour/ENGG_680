{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef_flon9qn5L"
      },
      "source": [
        "# Geometric Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRoDhRXGqn5N"
      },
      "source": [
        "## Sample Images\n",
        "\n",
        "`sklearn.datasets.load_sample_images()` is a function available in scikit-learn, a widely used Python machine learning library [scikit-learn Developers, 2023]. Detailed information about this function can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html). This function is used to load a collection of sample images, which can be useful for testing and experimenting with image-based machine learning algorithms and data analysis pipelines.\n",
        "\n",
        "When you call `load_sample_images()`, it retrieves a predefined set of sample images that are bundled with the scikit-learn library. These images cover a range of subjects and formats, providing a diverse set of data for practicing and developing image processing, computer vision, and machine learning techniques.\n",
        "\n",
        "The loaded images are usually provided as a dictionary-like object, containing the images themselves, information about the images, and sometimes additional metadata. This allows you to quickly access and work with the sample images for various tasks.\n",
        "If you're interested, you can access the detailed documentation for this image dataset [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynEo68pIqn5N"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt  # Import the plotting library\n",
        "from sklearn.datasets import load_sample_images  # Import a function to load sample images\n",
        "\n",
        "# Define a function to display images with titles and optional settings\n",
        "def ImShow(Images, Names, title='Images', grayscale=False, figsize=(9.5, 4.0)):\n",
        "    # Create a figure with two subplots\n",
        "    fig, ax = plt.subplots(1, 2, figsize= figsize)  # Create a figure with 1 row and 2 columns of subplots\n",
        "    ax = ax.ravel()  # Flatten the subplots for easier manipulation\n",
        "\n",
        "    # Iterate over the first two images\n",
        "    for i in range(2):\n",
        "        # Display the image in grayscale if grayscale is True, otherwise in color\n",
        "        ax[i].imshow(Images[i], cmap='gray' if grayscale else None)\n",
        "        ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n",
        "        ax[i].axis('off')  # Turn off axis\n",
        "        ax[i].set_title(Names[i], weight='bold')  # Set image title with bold font\n",
        "\n",
        "    if title:\n",
        "        # Set main title if provided\n",
        "        fig.suptitle(title, weight='bold', fontsize=18)\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout for better spacing\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Load sample images\n",
        "Images = load_sample_images()['images']  # Load the sample images\n",
        "# Extract image names from file paths, removing extension and converting to title case\n",
        "Names = [x.split(\"/\")[-1].replace('.jpg', '').title() for x in load_sample_images()['filenames']]\n",
        "\n",
        "# Display the original images\n",
        "_, _ = ImShow(Images, Names, title='Original Images')  # Call the ImShow function to display images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "170PoaQrqn5O"
      },
      "source": [
        "## Affine Transformations\n",
        "\n",
        "An affine transformation is a fundamental concept in image processing used to represent various geometric operations. It combines linear transformations (matrix multiplication) with translations (vector addition) to achieve versatile effects {cite:p}`OpenCVDocumentation`:\n",
        "\n",
        "1. **Rotations**: Employing linear transformations to rotate the image.\n",
        "2. **Translations**: Achieved by adding a vector, effectively shifting the image.\n",
        "3. **Scale Operations**: Applying linear transformations to resize the image.\n",
        "\n",
        "At its core, an affine transformation describes the relationship between two images. This transformation is typically represented by a 2x3 matrix {cite:p}`OpenCVDocumentation`:\n",
        "\n",
        "\\begin{equation}\n",
        "A = \\begin{bmatrix} a_{00} & a_{01} \\\\ a_{10} & a_{11} \\end{bmatrix}_{2 \\times 2} \\quad B = \\begin{bmatrix} b_{00} \\\\ b_{10} \\end{bmatrix}_{2 \\times 1}\n",
        "\\end{equation}\n",
        "\n",
        "We combine these matrices to form a 2x3 matrix:\n",
        "\n",
        "\\begin{equation}\n",
        "M = \\begin{bmatrix} A & B \\end{bmatrix} = \\begin{bmatrix} a_{00} & a_{01} & b_{00} \\\\ a_{10} & a_{11} & b_{10} \\end{bmatrix}_{2 \\times 3}\n",
        "\\end{equation}\n",
        "\n",
        "To transform a 2D vector $X = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$ using A and B, we can use:\n",
        "\n",
        "\\begin{equation}\n",
        "T = A \\cdot X + B\n",
        "\\end{equation}\n",
        "\n",
        "This results in:\n",
        "\n",
        "\\begin{equation}\n",
        "T = \\begin{bmatrix} a_{00}x + a_{01}y + b_{00} \\\\ a_{10}x + a_{11}y + b_{10} \\end{bmatrix}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aforementioned transformation may be alternatively expressed as follows. Given an input 2D vector $\\mathbf{X} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$, the transformation $T$ can be succinctly defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}x' \\\\ y' \\end{bmatrix}=M \\mathbf{X^*}\n",
        "= \\begin{bmatrix} a_{00}x + a_{01}y + b_{00} \\\\ a_{10}x + a_{11}y + b_{10} \\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Where:\n",
        "\n",
        "- $M$ denotes the 2x3 matrix:\n",
        "\n",
        "\\begin{equation}\n",
        "M = \\begin{bmatrix} A & B \\end{bmatrix} = \\begin{bmatrix} a_{00} & a_{01} & b_{00} \\\\ a_{10} & a_{11} & b_{10} \\end{bmatrix}_{2 \\times 3}\n",
        "\\end{equation}\n",
        "\n",
        "- $\\mathbf{X}$ represents the input vector:\n",
        "\n",
        "\\begin{equation} \\mathbf{X} = \\begin{bmatrix} x \\\\y \\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $\\mathbf{X^*}$ signifies an augmented form of the input vector:\n",
        "\n",
        "\\begin{equation} \\mathbf{X} = \\begin{bmatrix} x \\\\y \\\\ 1 \\end{bmatrix}\n",
        "\\end{equation}\n",
        "- $x'$ and $y'$ denote the transformed coordinates, which are the outcomes of applying the affine transformation $T$ to the input vector $\\mathbf{X}$."
      ],
      "metadata": {
        "id": "LJFg5iEz67Ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affine transformations provide a powerful framework for image manipulation, enabling operations such as rotation, translation, scaling, and more. They form the basis for transforming images efficiently and systematically.\n",
        "\n",
        "\n",
        "* **Translation Transformations:**\n",
        "\n",
        "\\begin{equation}\n",
        "A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}_{2 \\times 2} \\quad B = \\begin{bmatrix} b_{00} \\\\ b_{10} \\end{bmatrix}_{2 \\times 1}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "* **Rotation Transformations (for positive angles being clockwise rotations:)**\n",
        "\n",
        "\\begin{equation}\n",
        "A = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix}_{2 \\times 2} \\quad B = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}_{2 \\times 1}\n",
        "\\end{equation}\n",
        "\n",
        "* **Scaling Transformations:**\n",
        "\\begin{equation}\n",
        "A = \\begin{bmatrix} a_{00} & 0 \\\\ 0 & a_{11} \\end{bmatrix}_{2 \\times 2} \\quad B = \\begin{bmatrix} b_{00} \\\\ b_{10} \\end{bmatrix}_{2 \\times 1}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "l5JsS_hQ5vjn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWjPQV9yqn5O"
      },
      "source": [
        "### How to Derive an Affine Transformation?\n",
        "\n",
        "An Affine Transformation represents a fundamental relationship between two images. This connection can be established through different means, generally falling into two categories [OpenCV Developers, 2023]:\n",
        "\n",
        "1. **When We Know Both $X$ and $T$**: In this scenario, we possess knowledge about both sets of points, X and T, and we are aware that these points are related. Our objective is to find the transformation matrix, denoted as $M$.\n",
        "\n",
        "2. **When We Know $X$ and $M$**: If we have information about the transformation matrix $M$ and the original set of points $X$, we can easily obtain the transformed set of points $T$ by applying the transformation equation $T = MX$. This information for $M$ can either be explicit, represented as a 2-by-3 matrix, or it may be inferred from a geometric relationship between points.\n",
        "\n",
        "To elucidate the concept further, let's delve into the scenario described in point (b). When $M$ is the relationship that connects two images, we can analyze the simplest case where $M$ relates three distinct points in both images. Consider the visual representation below [OpenCV Developers, 2023]:\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/Warp_Affine_0.png\" alt=\"picture\" width=\"500\">\n",
        "\n",
        "Image courtesy of [OpenCV Developers, 2023].\n",
        "</center>\n",
        "\n",
        "\n",
        "In the image, points 1, 2, and 3 form a triangle in image 1. This same triangle, when mapped into image 2 through the Affine Transformation, undergoes a noticeable change. By determining the Affine Transformation using these three chosen points (which can be selected as needed), we can establish this discovered relationship for all pixels within an image.\n",
        "\n",
        "This methodology empowers us to apply the same transformation across the entire image, enabling geometric alterations such as rotations, translations, and scaling. Understanding this relationship between points and the transformation matrix forms the foundation for systematically manipulating images with Affine Transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Kzi7ECqn5O"
      },
      "source": [
        "### getAffineTransform\n",
        "\n",
        "The function `cv2.getAffineTransform(src, dst)` is a part of the OpenCV library in Python, and it's used to calculate the Affine Transformation matrix that maps points from one plane (source, `src`) to another plane (destination, `dst`). The Affine Transformation is a linear transformation that involves rotation, translation, and scaling. This transformation matrix can then be used to warp or transform images, shapes, or sets of points from the source plane to the destination plane {cite:p}`opencv_library, OpenCVDocumentation`.\n",
        "\n",
        "Here's a breakdown of the function parameters and return value:\n",
        "\n",
        "1. `src`: The source points, which is a 3x2 array of floating-point coordinates representing the original points in the source plane. It should contain three points (rows), each with two coordinates (columns).\n",
        "\n",
        "2. `dst`: The destination points, which is also a 3x2 array of floating-point coordinates. These represent the corresponding points in the destination plane. Just like the source points, it should contain three points with two coordinates each.\n",
        "\n",
        "The function calculates the Affine Transformation matrix that best maps the source points to the destination points. This matrix is denoted by the return value `retval`, which is a 2x3 floating-point matrix representing the transformation. The `retval` matrix can be used for various purposes, such as warping images using `cv2.warpAffine()` or transforming sets of points.\n",
        "\n",
        "To use the Affine Transformation matrix obtained from `cv2.getAffineTransform()`, you'll typically apply it to an image or points using the `cv2.warpAffine()` function, which performs the actual transformation. This function uses the calculated matrix to apply the transformation to the image or points. You can find the full description of this function [here](https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69glmrxqqn5P"
      },
      "source": [
        "### Image Wrap\n",
        "\n",
        "The function you're referring to, `cv2.warpAffine()`, is part of the OpenCV library, which is a popular computer vision and image processing library in Python. This specific function is used for geometric image transformations, particularly affine transformations. Let's break down the parameters and its purpose:\n",
        "\n",
        "```\n",
        "cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
        "```\n",
        "\n",
        "Here's what each parameter does:\n",
        "\n",
        "1. `src`: This is the input image, which is the source image you want to apply the transformation to. It should be a NumPy array (image) in most cases.\n",
        "\n",
        "2. `M`: This parameter represents the transformation matrix. It's a 2x3 matrix that defines the affine transformation. The matrix includes parameters like scaling, rotation, translation, and shearing. The transformation matrix `M` is used to specify how each pixel in the source image should be mapped to the destination image.\n",
        "\n",
        "3. `dsize`: This is the size (width and height) of the output image (destination image) you want to create after applying the transformation. It's specified as a tuple (width, height).\n",
        "\n",
        "4. `dst` (optional): This is the output image where the transformed image will be stored. If not provided, a new image will be created to store the result.\n",
        "\n",
        "5. `flags` (optional): This parameter specifies the interpolation method to be used during the transformation. Different methods can be used to determine the pixel values of the output image at locations that do not exactly map to locations in the source image.\n",
        "\n",
        "6. `borderMode` (optional): This parameter determines how to handle pixels that fall outside the boundaries of the source image. It defines the border mode.\n",
        "\n",
        "7. `borderValue` (optional): When a pixel is outside the source image boundaries, this parameter specifies the value that should be used for the pixel.\n",
        "\n",
        "8. `-> dst`: This indicates that the function returns the destination image, which contains the result of the affine transformation.\n",
        "\n",
        "You can find the full description of this function [here](https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWg06ub0qn5P"
      },
      "source": [
        "<font color='Blue'><b>Example</b></font>:\n",
        "In this illustrative code snippet, we showcase Affine Image Transformation using `cv2.getAffineTransform` in Python, including the definition of source and destination points, calculation of the Affine Transformation matrix, and visualization of the original and transformed images. We use the sklearn [image dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images) to demonstrate basic operations using Open CV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APMy_mG5qn5P"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "# Load an example image\n",
        "Img = load_sample_image('flower.jpg')\n",
        "rows, cols, _ = Img.shape\n",
        "\n",
        "# Define the source points (original triangle)\n",
        "src_pts = np.float32([[50, 50],\n",
        "                      [200, 50],\n",
        "                      [50, 200]])\n",
        "\n",
        "# Define the destination points (how the triangle should be transformed)\n",
        "dst_pts = np.float32([[10, 100],\n",
        "                      [200, 50],\n",
        "                      [100, 250]])\n",
        "\n",
        "# Calculate the Affine Transformation matrix using cv2.getAffineTransform\n",
        "M = cv2.getAffineTransform(src_pts, dst_pts).round(2)\n",
        "print('Affine Transformation Matrix (M) =', M)\n",
        "\n",
        "# Apply the Affine Transformation to the image\n",
        "Out = cv2.warpAffine(Img, M, (cols, rows))\n",
        "\n",
        "# Display the original and transformed images with titles\n",
        "fig, ax = ImShow(Images=[Img, Out],\n",
        "                 Names=['Original Image', 'Transformed Image'],\n",
        "                 title='Example: Affine Transformation', grayscale=False)\n",
        "\n",
        "# Mark the source and destination points on the images\n",
        "_ = ax[0].scatter(src_pts[:, 0], src_pts[:, 1], color='red')  # Mark source points on the original image\n",
        "_ = ax[1].scatter(dst_pts[:, 0], dst_pts[:, 1], color='red')  # Mark destination points on the transformed image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT-Q1aeNqn5P"
      },
      "source": [
        "Given an input 2D vector $\\mathbf{X} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$, the transformation $T$ can be expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        "x' \\\\\n",
        "y'\n",
        "\\end{bmatrix}\n",
        "=\n",
        "M  \\mathbf{X}\n",
        "\\end{equation}\n",
        "\n",
        "Where:\n",
        "\n",
        "- $M$ is the following 2x3 matrix:\n",
        "\n",
        "\\begin{equation}\n",
        "M =\n",
        "\\begin{bmatrix}\n",
        "1.27 & 0.6 & -83.33 \\\\\n",
        "-0.33 & 1.0 & 66.67\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $\\mathbf{X}$ is the input vector:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "x \\\\\n",
        "y\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $x'$ and $y'$ are the transformed coordinates, which are the result of applying the affine transformation $T$ to the input vector $\\mathbf{X}$.\n",
        "\n",
        "To calculate $x'$ and $y'$, you perform the matrix multiplication as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        "x' \\\\\n",
        "y'\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1.27 & 0.6 & -83.33 \\\\\n",
        "-0.33 & 1.0 & 66.67\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x \\\\\n",
        "y \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $[x, y]$ represents a point in the original 2D plane, typically corresponding to a pixel location in the original image.\n",
        "\n",
        "- $[x', y']$ represents the transformed point in the 2D plane, which corresponds to the new location of the pixel after applying the affine transformation.\n",
        "\n",
        "$[x, y]$ are the coordinates of a point in the original image, and $[x', y']$ are the coordinates of the corresponding point in the transformed image after the affine transformation has been applied using the matrix $M$.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qjxXFbDqn5Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def Transformation(M, src_pts):\n",
        "    # Reshape src_pts for matrix multiplication\n",
        "    src_pts_reshaped = src_pts.T\n",
        "\n",
        "    # Apply the transformation matrix M to the source points\n",
        "    transformed_pts = M @ np.vstack((src_pts_reshaped, np.ones(src_pts.shape[0])))\n",
        "\n",
        "    # Transpose the result to obtain a 2x3 matrix\n",
        "    transformed_pts = transformed_pts.T\n",
        "\n",
        "    # transformed_pts now contains the transformed points in a 2x3 matrix\n",
        "    return transformed_pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGwOCBsNqn5Q"
      },
      "source": [
        "Note that if you use the above transfomratio, we get\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}x' \\\\y'\\end{bmatrix} &=\n",
        "\\begin{bmatrix}1.27 & 0.6 & -83.33 \\\\-0.33 & 1.0 & 66.67\\end{bmatrix}\n",
        "\\begin{bmatrix}50 \\\\50 \\\\ 1\\end{bmatrix}=\n",
        "\\begin{bmatrix}10 \\\\100\\end{bmatrix}\\\\\n",
        "%\n",
        "\\begin{bmatrix}x' \\\\y'\\end{bmatrix} &=\n",
        "\\begin{bmatrix}1.27 & 0.6 & -83.33 \\\\-0.33 & 1.0 & 66.67\\end{bmatrix}\n",
        "\\begin{bmatrix}200 \\\\50 \\\\ 1\\end{bmatrix}=\n",
        "\\begin{bmatrix}200 \\\\50\\end{bmatrix}\\\\\n",
        "%\n",
        "\\begin{bmatrix}x' \\\\y'\\end{bmatrix} &=\n",
        "\\begin{bmatrix}1.27 & 0.6 & -83.33 \\\\-0.33 & 1.0 & 66.67\\end{bmatrix}\n",
        "\\begin{bmatrix}50 \\\\200\\\\ 1\\end{bmatrix}=\n",
        "\\begin{bmatrix}100 \\\\250\\end{bmatrix}\\\\\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "Please note that all final outputs were rounded to the nearest whole integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWo7H_njqn5Q"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "print('src_pts:')\n",
        "pprint(src_pts)\n",
        "print('dst_pts:')\n",
        "pprint(Transformation(M, src_pts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XitetqLfqn5Q"
      },
      "source": [
        "<font color='Blue'><b>Example</b></font>:\n",
        "In this example, we demonstrate 2D Image Translation using `cv2.warpAffine` in Python, showcasing the transforming an image of an image using the following $M$:\n",
        "\n",
        "\\begin{equation}\n",
        "M =\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 10 \\\\\n",
        "0 & 1 & 20\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "where specified values of $b_{00} = 10$ and $b_{10} = 20$ and displaying both the original and transformed images with informative labels. We utilize the [image dataset function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images) from scikit-learn to showcase fundamental image manipulation operations using OpenCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "BGFBPNTAqn5Q"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "# Load the sample image\n",
        "Img = load_sample_image('flower.jpg')\n",
        "rows, cols, _ = Img.shape\n",
        "\n",
        "# Define a function to create a 2D translation matrix\n",
        "def map_matrix(tx, ty):\n",
        "    \"\"\"\n",
        "    Create a 2D translation matrix.\n",
        "\n",
        "    Args:\n",
        "        tx (float): Translation amount in the x-direction.\n",
        "        ty (float): Translation amount in the y-direction.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A 2x3 transformation matrix for translation.\n",
        "    \"\"\"\n",
        "    # Create a 2x3 transformation matrix with translation values (tx, ty)\n",
        "    M = np.eye(3, dtype=float)[:2, :]\n",
        "    M[:, -1] = [tx, ty]\n",
        "    return M\n",
        "\n",
        "# Apply the affine transformation to the image using warpAffine\n",
        "# with translation values tx = 10 and ty = 20\n",
        "tx = 10\n",
        "ty = 20\n",
        "M = map_matrix(tx, ty)\n",
        "print('Transformation Matrix (M) =', M)\n",
        "Out = cv2.warpAffine(Img, M, (cols, rows))\n",
        "\n",
        "# Display the original and transformed images with titles\n",
        "fig, ax = ImShow([Img, Out],\n",
        "                 ['Original Image', 'Translated Image ($b_{00}$ = %i, $b_{01}$ = %i)' % (tx, ty)],\n",
        "                 title='Example: Translation Transformation')\n",
        "\n",
        "# Define the source points (original triangle)\n",
        "src_pts = np.float32([[50, 50],\n",
        "                      [200, 50],\n",
        "                      [50, 200]])\n",
        "\n",
        "# Define the destination points (how the triangle should be transformed)\n",
        "dst_pts = Transformation(M, src_pts)\n",
        "# Mark the source and destination points on the images\n",
        "_ = ax[0].scatter(src_pts[:, 0], src_pts[:, 1], color='red')  # Mark source points on the original image\n",
        "_ = ax[1].scatter(dst_pts[:, 0], dst_pts[:, 1], color='red')  # Mark destination points on the transformed image\n",
        "\n",
        "# Add text indicating the size of the original and transformed images\n",
        "_ = ax[0].text(x=0, y=int(0.02 * Img.shape[1]), s=f'Size: {Img.shape[0]} by {Img.shape[1]}',\n",
        "               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))\n",
        "_ = ax[1].text(x=0, y=int(0.02 * Out.shape[1]), s=f'Size: {Out.shape[0]} by {Out.shape[1]}',\n",
        "               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<font color='Red'><b>Note:</b></font>\n",
        "\n",
        "It is essential to note that in this context, $t_x$ and $t_y$ are equivalent to $b_{00}$ and $b_{10}$ respectively, as represented by:\n",
        "\n",
        "\\begin{equation}\n",
        "B = \\begin{bmatrix} b_{00} \\\\ b_{10} \\end{bmatrix}_{2 \\times 1} \\text{ and }\n",
        "B = \\begin{bmatrix} t_{x} \\\\ t_{y} \\end{bmatrix}_{2 \\times 1}\n",
        "\\end{equation}\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uwZl9JD1GTNw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg4lnpeeqn5Q"
      },
      "source": [
        "Given an input 2D vector $\\mathbf{X} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$, the transformation $T$ can be expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        "x' \\\\\n",
        "y'\n",
        "\\end{bmatrix}\n",
        "=\n",
        "M \\mathbf{X^*}\n",
        "\\end{equation}\n",
        "\n",
        "Where:\n",
        "\n",
        "- $M$ is the 2x3 translation matrix created in the `map_matrix` function:\n",
        "\n",
        "\\begin{equation}\n",
        "M =\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & t_x \\\\\n",
        "0 & 1 & t_y\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $\\mathbf{X}$ is the input vector:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "x \\\\ y \\\\ 1\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $\\mathbf{X^*}$ signifies an augmented form of the input vector:\n",
        "\n",
        "\\begin{equation} \\mathbf{X} = \\begin{bmatrix} x \\\\y \\\\ 1 \\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- $x'$ and $y'$ are the transformed coordinates, which are the result of applying the translation transformation $T$ to the input vector $\\mathbf{X}$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this specific code:\n",
        "\n",
        "- $t_x$ and $t_y$ are the translation amounts in the x and y directions, respectively. These values are set to 10 and 20 in the code.\n",
        "- The `map_matrix` function creates the translation matrix $M$ with the specified translation values $(t_x, t_y)$.\n",
        "- The `cv2.warpAffine` function applies the translation transformation to the image using the matrix $M$.\n",
        "\n",
        "The result is a translated image where each pixel has been shifted by $tx$ units in the x-direction and $ty$ units in the y-direction.\n",
        "***"
      ],
      "metadata": {
        "id": "nt6RN6TCDMCX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMk_hFQaqn5R"
      },
      "source": [
        "### getRotationMatrix2D\n",
        "\n",
        "In computer vision and image processing, the `cv2.getRotationMatrix2D` function, provided by the OpenCV library, is a valuable tool for computing a 2D rotation matrix. This matrix facilitates image rotations with precise control over the angle and scaling factor.\n",
        "\n",
        "The function requires three primary arguments:\n",
        "\n",
        "1. `center`: This parameter specifies the rotation center, typically represented as a tuple (x, y) denoting the coordinates of the central point around which the image will rotate.\n",
        "\n",
        "2. `angle`: The rotation angle is defined in degrees. **A positive angle value indicates counterclockwise rotation, while a negative angle value signifies a clockwise rotation**.\n",
        "\n",
        "3. `scale`: The scaling factor applied to the image after rotation. It allows for resizing the image during the rotation process. A scale of 1 preserves the original size, values greater than 1 increase it, and values less than 1 decrease it.\n",
        "\n",
        "The function returns a 2x3 transformation matrix commonly referred to as the \"rotation matrix.\" This matrix encapsulates the geometric transformations necessary to achieve the specified rotation and scaling effects.\n",
        "\n",
        "Mathematically, the rotation matrix is expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        "\\alpha & \\beta & (1 - \\alpha) \\cdot \\texttt{center.x} - \\beta \\cdot \\texttt{center.y} \\\\\n",
        "- \\beta & \\alpha & \\beta \\cdot \\texttt{center.x} + (1 - \\alpha) \\cdot \\texttt{center.y}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Where:\n",
        "- $\\alpha = \\texttt{scale} \\cdot \\cos(\\texttt{angle})$\n",
        "- $\\beta = \\texttt{scale} \\cdot \\sin(\\texttt{angle})$\n",
        "\n",
        "This transformation preserves the rotation center at its original position. If the objective is to change the rotation center, you can adjust the shift accordingly.\n",
        "\n",
        "For a more comprehensive understanding of this function, please refer to [this link](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#gafbbc470ce83812914a70abfb604f4326)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkojgiRQqn5R"
      },
      "source": [
        "<font color='Blue'><b>Example:</b></font> In this example, we load an image, rotate it by 25 degrees, and display both the original and rotated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1co36Yxqn5R"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "# Load the sample image\n",
        "Img = load_sample_image('flower.jpg')\n",
        "\n",
        "# Rotate the image by 25 degrees\n",
        "rows, cols, _ = Img.shape\n",
        "angle = 25  # Specify the rotation angle\n",
        "scale = 1.0  # Scale factor (1.0 maintains the original size)\n",
        "rotation_center = (cols // 2, rows // 2)  # Center of the image\n",
        "print('rotation_center:')\n",
        "print(rotation_center)\n",
        "\n",
        "# Get the rotation matrix using cv2.getRotationMatrix2D\n",
        "M = cv2.getRotationMatrix2D(rotation_center, angle, scale)\n",
        "print('Affine Transformation Matrix (M) =', M)\n",
        "\n",
        "# Apply the affine transformation to the image using warpAffine\n",
        "Out = cv2.warpAffine(Img, M, (cols, rows))  # Transformed image\n",
        "\n",
        "# Display the original and rotated images\n",
        "fig, ax = ImShow([Img, Out],\n",
        "                 ['Original Image', 'Rotated Image'],\n",
        "                 title=f'Image Rotation by {angle} Degrees')\n",
        "\n",
        "# Define the source points (original triangle)\n",
        "src_pts = np.float32([[50, 50],\n",
        "                      [200, 50],\n",
        "                      [50, 200]])\n",
        "\n",
        "# Define the destination points (how the triangle should be transformed)\n",
        "dst_pts = Transformation(M, src_pts)\n",
        "# Mark the source and destination points on the images\n",
        "_ = ax[0].scatter(src_pts[:, 0], src_pts[:, 1], color='red')  # Mark source points on the original image\n",
        "_ = ax[1].scatter(dst_pts[:, 0], dst_pts[:, 1], color='red')  # Mark destination points on the transformed image\n",
        "\n",
        "# Add text indicating the size of the original and transformed images\n",
        "_ = ax[0].text(x=0, y=int(0.02 * Img.shape[1]), s=f'Size: {Img.shape[0]} by {Img.shape[1]}',\n",
        "               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))\n",
        "_ = ax[1].text(x=0, y=int(0.02 * Out.shape[1]), s=f'Size: {Out.shape[0]} by {Out.shape[1]}',\n",
        "               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znj_FKiQqn5R"
      },
      "source": [
        "Based on the provided values of $\\theta = 25$ (in degrees) and $\\text{scale} = 1$, the resulting 2D rotation matrix $M$ can be calculated as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        "\\alpha & \\beta & (1 - \\alpha) \\cdot \\text{center.x} - \\beta \\cdot \\text{center.y} \\\\\n",
        "- \\beta & \\alpha & \\beta \\cdot \\text{center.x} + (1 - \\alpha) \\cdot \\text{center.y}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\alpha = \\text{scale} \\cdot \\cos(\\theta)$\n",
        "- $\\beta = \\text{scale} \\cdot \\sin(\\theta)$\n",
        "\n",
        "Given that $\\theta = 25$ degrees and $\\text{scale} = 1$, you can calculate $\\alpha$ and $\\beta$ as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha = 1 \\cdot \\cos(25^\\circ) \\approx 0.90630779\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\beta = 1 \\cdot \\sin(25^\\circ) \\approx 0.42261826\n",
        "\\end{equation}\n",
        "\n",
        "Now, you can calculate the elements of the rotation matrix $M$ using these values and the center point $(320, 213)$:\n",
        "\n",
        "\\begin{equation}\n",
        "M = \\begin{bmatrix}\n",
        "0.90630779 & 0.42261826 & (1 - 0.90630779) \\cdot 320 - 0.42261826 \\cdot 213 \\\\\n",
        "-0.42261826 & 0.90630779 & 0.42261826 \\cdot 320 + (1 - 0.90630779) \\cdot 213\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "The resulting matrix $M$ will be:\n",
        "\n",
        "\\begin{equation}\n",
        "M = \\begin{bmatrix}\n",
        "0.90630779 & 0.42261826 & -60.0361816 \\\\\n",
        "-0.42261826 & 0.90630779 & 155.19428512\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "This is the 2D rotation matrix $M$ corresponding to a rotation angle of 25 degrees and a scale factor of 1.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEtOd_IVqn5R"
      },
      "source": [
        "## Resizing Images with OpenCV\n",
        "\n",
        "The `resize` function in OpenCV is a versatile tool for adjusting the size of images, whether making them smaller or larger. It offers several options for defining the output size or using scaling factors to control the resizing process, providing the flexibility needed for various image manipulation tasks {cite:p}`opencv_library, OpenCVDocumentation`.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "The `resize` function is essential for handling image dimensions. Here's a breakdown of its capabilities:\n",
        "\n",
        "1. **Resizing an Image:**\n",
        "   The primary purpose of `resize` is to change the size of an image. This can involve reducing or increasing the image's dimensions. The function allows explicit size specification or resizing based on scaling factors (`fx` and `fy`). Importantly, the initial type or size of the output image (`dst`) is not used. Instead, it's determined based on the source image (`src`), the desired output size (`dsize`), and the specified scaling factors.\n",
        "\n",
        "2. **Explicit Output Size:**\n",
        "   If you want to resize `src` to fit a pre-created destination image `dst`, you can achieve this by calling the function as follows:\n",
        "   ```python\n",
        "   resize(src, dst, dst.size(), 0, 0, interpolation)\n",
        "   ```\n",
        "   Here, `dsize` is set to match the size of `dst`, and the scaling factors `fx` and `fy` are automatically computed based on that.\n",
        "\n",
        "3. **Using Scaling Factors:**\n",
        "   You can also use scaling factors to control the resizing process. For instance, to decrease the size of the image by a factor of 2 in both the horizontal and vertical directions (decimation), you can use the following approach:\n",
        "   ```python\n",
        "   resize(src, dst, Size(), 0.5, 0.5, interpolation)\n",
        "   ```\n",
        "   Here, `fx` and `fy` are explicitly specified, and the function calculates the destination image size based on these factors.\n",
        "\n",
        "4. **Selecting Interpolation:**\n",
        "   When shrinking an image, the `INTER_AREA` interpolation method is recommended for the best results in terms of image quality. On the other hand, when enlarging an image, using `INTER_CUBIC` (higher quality, but slower) or `INTER_LINEAR` (faster but still acceptable quality) interpolation methods is generally recommended.\n",
        "\n",
        "**Function Parameters:**\n",
        "\n",
        "- `src`: The input image to be resized.\n",
        "- `dst`: The output image. Its size can be explicitly set using `dsize`, or it can be determined automatically based on `src.size()`, `fx`, and `fy`. The type of `dst` matches the type of `src`.\n",
        "- `dsize`: The desired output image size. If set to zero (None in Python), the function calculates it as:\n",
        "  ```\n",
        "  dsize = Size(round(fx * src.cols), round(fy * src.rows))\n",
        "  ```\n",
        "  Either `dsize` or both `fx` and `fy` must be non-zero.\n",
        "- `fx`: The scaling factor along the horizontal axis (width). If `fx` is 0, it's computed as `(double)dsize.width / src.cols`.\n",
        "- `fy`: The scaling factor along the vertical axis (height). If `fy` is 0, it's computed as `(double)dsize.height / src.rows`.\n",
        "- `interpolation`: The interpolation method used during the resizing operation (e.g., `INTER_NEAREST`, `INTER_LINEAR`, `INTER_CUBIC`, `INTER_LANCZOS4`).\n",
        "\n",
        "The `resize` function allows you to resize images while maintaining control over the output size and selecting appropriate interpolation methods to achieve the desired quality.\n",
        "\n",
        "**Syntax:**\n",
        "\n",
        "```\n",
        "cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) -> dst\n",
        "```\n",
        "\n",
        "Here's what each parameter does:\n",
        "\n",
        "1. `src`: The input image that you want to resize. It should be a NumPy array (image) in most cases.\n",
        "\n",
        "2. `dsize`: The desired size (width and height) of the output image. It's specified as a tuple (width, height). If you provide this parameter, the `fx` and `fy` parameters (scaling factors) are ignored.\n",
        "\n",
        "3. `dst` (optional): The output image where the resized image will be stored. If not provided, a new image will be created to store the result.\n",
        "\n",
        "4. `fx` (optional): The scale factor along the horizontal axis (width) by which you want to resize the image. If you provide `fx`, the `dsize` parameter is ignored on that axis.\n",
        "\n",
        "5. `fy` (optional): The scale factor along the vertical axis (height) by which you want to resize the image. If you provide `fy`, the `dsize` parameter is ignored on that axis.\n",
        "\n",
        "6. `interpolation` (optional): The interpolation method to be used during the resizing operation. Interpolation determines how pixel values are computed for the output image based on the input image. Common [interpolation](https://en.wikipedia.org/wiki/Bicubic_interpolation) methods include:\n",
        "\n",
        "   - `cv2.INTER_NEAREST`: Nearest-neighbor interpolation (fast but may produce blocky results).\n",
        "   - `cv2.INTER_LINEAR`: Bilinear interpolation (good for most general-purpose resizing).\n",
        "   - `cv2.INTER_CUBIC`: Bicubic interpolation (better quality, but slower).\n",
        "   - `cv2.INTER_LANCZOS4`: Lanczos interpolation (high-quality but slower).\n",
        "\n",
        "The `cv2.resize()` function resizes the input image based on the specified size or scaling factors and the chosen interpolation method. The function returns the resized image, and if you provided the `dst` parameter, the resized image is stored in the `dst` array; otherwise, a new image is created and returned. The `dst` parameter allows you to reuse an existing image array for efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-HPie7xqn5R"
      },
      "source": [
        "<font color='Blue'><b>Example:</b></font> In this example, we'll explore an image processing task that involves resizing an image using cubic interpolation. Cubic interpolation is a method for resizing images while maintaining smooth transitions between pixels. We'll load a sample image, apply the resizing operation, and visualize both the original and resized images. Additionally, we'll add text annotations to display the sizes of the original and resized images for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "vChXnPXdqn5S"
      },
      "outputs": [],
      "source": [
        "# Load the sample image 'china.jpg'\n",
        "Img = load_sample_image('china.jpg')\n",
        "\n",
        "# Resize the original image using cubic interpolation\n",
        "Out = cv2.resize(Img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# Display the original and resized images with titles\n",
        "fig, ax = ImShow([Img, Out], ['Original Image', 'Resized Image'], title='Image Resize')\n",
        "\n",
        "# Add text indicating the size of the original and resized images\n",
        "_ = ax[0].text(x=0, y=int(0.02 * Img.shape[1]), s=f'Size: {Img.shape[0]} by {Img.shape[1]}',\n",
        "               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))\n",
        "_ = ax[1].text(x=0, y=int(0.02 * Out.shape[1]), s=f'Size: {Out.shape[0]} by {Out.shape[1]}',\n",
        "               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}