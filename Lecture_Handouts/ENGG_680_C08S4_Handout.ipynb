{"cells":[{"cell_type":"markdown","metadata":{"id":"_GJR_hqauvUC"},"source":["# Image Filtering\n","\n","Image filtering is a fundamental concept in computer vision and image processing. It involves applying a filter (also known as a kernel) to an image in order to perform operations such as blurring, sharpening, edge detection, and more. The OpenCV library (cv2) in Python is a powerful tool for image processing, including image filtering."]},{"cell_type":"markdown","metadata":{"id":"FwW4Ngg0uvUD"},"source":["## Smoothing Images"]},{"cell_type":"markdown","metadata":{"id":"J75lVuZruvUE"},"source":["Image smoothing, also known as blurring, is a widely used image processing technique. It's employed to decrease noise, suppress fine details, or ready an image for subsequent analysis. To continue with the following steps, we'll use the following reference image and its noisy variant."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2XWv6_TuvUE"},"outputs":[],"source":["# Import necessary libraries\n","import matplotlib.pyplot as plt  # Import the plotting library\n","\n","# Define color codes for convenience\n","Colors = {'White': (255, 255, 255),\n","            'Black': (0, 0, 0),\n","            'Red': (255, 0, 0),\n","            'Green': (0, 255, 0),\n","            'Blue': (0, 0, 255),\n","            'Yellow': (255, 255, 0),\n","            'Purple': (128, 0, 128),\n","            'Indigo': (75, 0, 130),\n","            'OrangeRed': (255, 69, 0)}\n","\n","# Define a function to display images with titles and optional settings\n","def ImShow(Images, Names, title='Images', grayscale=False):\n","    # Create a figure with two subplots\n","    fig, ax = plt.subplots(1, 2, figsize=(9.5, 4))  # Create a figure with 1 row and 2 columns of subplots\n","    ax = ax.ravel()  # Flatten the subplots for easier manipulation\n","\n","    # Iterate over the first two images\n","    for i in range(2):\n","        # Display the image in grayscale if grayscale is True, otherwise in color\n","        ax[i].imshow(Images[i], cmap='gray' if grayscale else None)\n","        ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n","        ax[i].axis('off')  # Turn off axis\n","        ax[i].set_title(Names[i], weight='bold')  # Set image title with bold font\n","\n","    if title:\n","        # Set main title if provided\n","        fig.suptitle(title, weight='bold', fontsize=18)\n","\n","    plt.tight_layout()  # Adjust layout for better spacing\n","\n","    return fig, ax"]},{"cell_type":"markdown","metadata":{"id":"XAQNRFgfuvUE"},"source":["<font color='Blue'><b>Example - Noisy Image:</b></font> For the following example, we employ an image depicting the main campus of the University of Calgary, accessible at https://conted.ucalgary.ca/maincampus/maincampus.jpg."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Nyo6Z8kuvUF"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","import cv2\n","from skimage import io\n","\n","# Load an image from a URL\n","Img = io.imread(r'https://conted.ucalgary.ca/maincampus/maincampus.jpg')\n","\n","# Define a function that standardizes image values\n","def ImgStd(Inp):\n","    '''\n","    Standardizes image values.\n","\n","    Parameters:\n","        Inp (numpy.ndarray): Input image.\n","\n","    Returns:\n","        numpy.ndarray: Standardized image.\n","    '''\n","    Out = np.round(Inp).astype(int)  # Round the input values and convert to integers\n","    Out[Out < 0] = 0  # Set any negative values to 0\n","    Out[Out > 255] = 255  # Set any values above 255 to 255 (maximum pixel value)\n","    return Out  # Return the standardized image\n","\n","# Define the parameters for generating a noisy image\n","mu = 0  # Mean of the noise\n","sigma = 30  # Standard deviation of the noise\n","\n","# Create a noisy image by adding Gaussian noise to a copy of the original image\n","Img_noise = Img.copy() - np.random.normal(mu, sigma, size=Img.shape)\n","\n","# Standardize the noisy image using the defined ImgStd function\n","Img_noise = ImgStd(Img_noise).astype('uint8')\n","\n","# Display the original image and the noisy image side by side\n","_ = ImShow(Images=[Img, Img_noise],\n","           Names=['UofC', 'UofC + Noise'],\n","           title= 'Image and Noisy Image')"]},{"cell_type":"markdown","metadata":{"id":"OEksvvgBuvUG"},"source":["### 2D Convolution (Image Filtering)\n","\n","\n","1. **Padding**:\n","   Padding is a technique used in convolutional operations to control the spatial dimensions of the output feature map. It involves adding extra rows and columns of zeros around the input image before applying the convolution operation. Padding is typically used to:\n","\n","   - **Preserve Spatial Dimensions**: Padding helps maintain the spatial dimensions of the output feature map, ensuring that it has the same size as the input. This can be important when you want to preserve spatial information.\n","\n","   - **Mitigate Boundary Effects**: Without padding, the convolution operation tends to lose information near the image borders. Padding helps mitigate this issue by allowing the kernel to process pixels at the image boundaries more effectively.\n","\n","   In OpenCV (cv2), you can specify the type of padding you want when using the `cv2.filter2D()` function. Common padding modes include 'valid' (no padding), 'same' (padding to match the output size with the input size), and 'full' (maximum padding to ensure the kernel covers the entire input).\n","\n","2. **Strides**:\n","   Strides determine how the convolutional kernel moves or steps across the input image during the convolution operation. A stride value of 1 means the kernel moves one pixel at a time, while a stride value greater than 1 means it skips some pixels.\n","\n","   - **Stride of 1**: A stride of 1 processes each pixel in the input image, resulting in output feature maps with similar spatial dimensions as the input.\n","\n","   - **Stride greater than 1**: A larger stride value skips pixels, resulting in output feature maps with reduced spatial dimensions. This can be useful for downsampling and reducing computational complexity.\n","\n","In OpenCV (cv2), you can specify the stride when using the `cv2.filter2D()` function. By default, the stride is set to 1, but you can modify it to control the spatial downsampling or upsampling effect."]},{"cell_type":"markdown","metadata":{"id":"FmVs1sm-uvUG"},"source":["<center>\n","<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/Conv3by3.gif\" alt=\"picture\" width=\"450\">\n","\n","Illustration of the convolution process using a 3 by 3 kernel applied to a 5 by 5 matrix with a stride of 1 and padding of 1. Image courtesy of [Dumoulin and Visin, 2016, Shafkat, 2023].\n","\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"xjF14xF1uvUG"},"source":["***\n","<font color='Red'><b>Remark:</b></font>\n","\n","To determine the size of padding required based on the size of the kernel and the desired stride, you can use the following formula:\n","\n","\\begin{equation} \\text{Padding size} = \\left\\lfloor \\frac{\\text{Kernel size} - 1}{2} \\right\\rfloor \\times \\text{Stride} \\end{equation}\n","\n","Here's what each component means:\n","\n","- **Padding size**: This is the size of the padding you need to add to the input image or matrix.\n","- **Kernel size**: This refers to the dimensions of your convolutional kernel. For example, a 3x3 kernel has a size of 3.\n","- **Stride**: The stride determines how much the kernel moves between each convolution operation. A stride of 1 means it moves one step at a time.\n","\n","Let's consider an example:\n","\n","Suppose you have a 3x3 kernel and you want to apply it with a stride of 2. Using the formula:\n","\n","\\begin{equation} \\text{Padding size} = \\left\\lfloor \\frac{3 - 1}{2} \\right\\rfloor \\times 2 = \\left\\lfloor \\frac{2}{2} \\right\\rfloor \\times 2 = 1 \\times 2 = 2 \\end{equation}\n","\n","Thus, in this case, you would need to add a padding of 2 units around your input image or matrix to achieve the desired stride of 2 while maintaining the dimensions.\n","***"]},{"cell_type":"markdown","metadata":{"id":"8em0gVCiuvUG"},"source":["The Python function `cv2.filter2D()` is a method from the OpenCV (Open Source Computer Vision Library) used for applying a custom convolutional filter to an input image (source) in order to perform image processing operations. Here's a refined explanation of its parameters and return value:\n","\n","```\n","cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) → dst\n","```\n","\n","- **src**: This parameter represents the input image, often referred to as the \"source\" image, on which the filter operation is applied. It's a mandatory argument and should be a multi-channel image (e.g., RGB or grayscale).\n","\n","- **ddepth**: This specifies the desired depth of the output image (destination). It determines the data type of the destination image, which can be different from the source image. Common data types include `cv2.CV_8U` for 8-bit unsigned integers, `cv2.CV_32F` for 32-bit floating-point numbers, etc.\n","\n","- **kernel**: The kernel is a user-defined convolution matrix that defines the filter's behavior. This parameter is essential and should be a numerical matrix (numpy array) used for filtering the source image. The kernel defines the weights applied to the image pixels to compute the output.\n","\n","- **dst** (optional): This is the destination image, which is where the filtered result is stored. If not provided, the function creates a new image to store the result. It should have the same size and type as the source image.\n","\n","- **anchor** (optional): This parameter denotes the relative position within the kernel. It specifies the anchor point with respect to which the convolution operation is performed. The anchor point determines the alignment of the kernel over the source image.\n","\n","- **delta** (optional): The value added to the filtered pixels, which can be used for contrast adjustment or to shift the intensity range of the output image.\n","\n","- **borderType** (optional): This parameter determines the border mode applied when the kernel extends beyond the edges of the source image. Common border types include constant border, replicate border, reflect border, etc.\n","\n","- **Returns**: The function returns the filtered image, which is the result of applying the specified kernel to the input image. The destination image (dst) contains the filtered output.\n","\n","You can see the full description of the function [here](https://docs.opencv.org/2.4/modules/ocl/doc/image_filtering.html?highlight=filter2d#ocl-filter2d)."]},{"cell_type":"markdown","metadata":{"id":"Bar_rOsDuvUG"},"source":["<font color='Blue'><b>Example</b></font>:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFrQfo7XuvUH"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np  # Import NumPy for array operations\n","import cv2  # Import OpenCV for image processing\n","\n","# Define a kernel for filtering (5x5 averaging kernel)\n","kernel = np.ones((5, 5), np.float32) / 25\n","\n","# Apply the filter2D operation to the original image\n","Out = cv2.filter2D(src=Img,  # Source image\n","                   ddepth=-1,  # Use the same depth as the source image\n","                   kernel=kernel  # 2D array of filter coefficients\n","                   )\n","\n","# Display the original noisy image and the filtered image side by side\n","fig, ax = ImShow(Images=[Img, Out], Names=['UofC', 'Filter2D (UofC)'], title='Filter 2D on Original Image')\n","\n","# Add text indicating the size of the original and transformed images\n","_ = ax[0].text(x=0, y=int(0.02 * Img.shape[1]), s=f'Size: {Img.shape[0]} by {Img.shape[1]}',\n","               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))\n","_ = ax[1].text(x=0, y=int(0.02 * Out.shape[1]), s=f'Size: {Out.shape[0]} by {Out.shape[1]}',\n","               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))\n","\n","# Apply the filter2D operation to the noisy image\n","Out = cv2.filter2D(src=Img_noise,  # Source image with noise\n","                   ddepth=-1,  # Use the same depth as the source image\n","                   kernel=kernel  # 2D array of filter coefficients\n","                   )\n","\n","# Display the original noisy image and the filtered image side by side\n","fig, ax = ImShow(Images=[Img_noise, Out], Names=['UofC + Noise', 'Filter2D (UofC + Noise)'], title='Filter 2D on Noisy Image')\n","\n","# Add text indicating the size of the original and transformed images\n","_ = ax[0].text(x=0, y=int(0.02 * Img.shape[1]), s=f'Size: {Img.shape[0]} by {Img.shape[1]}',\n","               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))\n","_ = ax[1].text(x=0, y=int(0.02 * Out.shape[1]), s=f'Size: {Out.shape[0]} by {Out.shape[1]}',\n","               size=11, color='Navy', bbox=dict(boxstyle=\"square\", ec='Navy', fc='LightSkyBlue'))"]},{"cell_type":"markdown","metadata":{"id":"vU5NT-zUuvUH"},"source":["## Image Blurring (Image Smoothing)\n","\n","Image blurring, also known as image smoothing or image filtering, is a fundamental image processing technique employed to mitigate high-frequency components within an image, such as noise and edges. Its primary purpose is to eliminate undesired details, resulting in a more visually cohesive and smoother appearance. Various blurring methods exist, each serving distinct purposes [Bradski, 2000, OpenCV Developers, 2023]:\n","\n","1. **Gaussian Blur**: This technique employs a Gaussian kernel that convolves with the image pixels, producing a weighted average of neighboring pixels. These weights are determined by the Gaussian distribution, making it adept at reducing high-frequency noise while preserving image structure.\n","\n","2. **Median Blur**: In this approach, every pixel in the image is replaced with the median value of its neighboring pixels. It is particularly effective in removing \"salt-and-pepper\" noise, where isolated pixels have extreme intensity values, leading to a cleaner image.\n","\n","3. **Bilateral Filter**: A non-linear filter that considers both spatial and intensity differences during the blurring process. It excels at noise reduction while retaining the sharpness of significant image features and edges.\n","\n","4. **Box Blur**: Also known as average blur, this method replaces each pixel with the average value of its neighboring pixels. While providing a simple and uniform blurring effect, it may not preserve intricate image details as effectively as other methods.\n","\n","5. **Motion Blur**: Simulates the effect of camera or object motion, creating streak-like artifacts within the image. This blurring technique imparts a sense of movement and dynamics to the scene.\n","\n","These diverse blurring methods can be implemented using a range of image processing libraries, such as OpenCV in the Python programming language. The choice of a specific blurring technique hinges on the unique requirements of the application and the intrinsic characteristics of the image content, allowing practitioners to tailor the approach to their specific needs."]},{"cell_type":"markdown","metadata":{"id":"kjP4Ai7WuvUJ"},"source":["This code creates a visual comparison of the original image and the image obtained by applying the `cv2.boxFilter` operation with different kernel sizes. The results are displayed in a 2x2 grid of subplots, each with appropriate titles and annotations indicating the kernel size used."]},{"cell_type":"markdown","metadata":{"id":"cjwE4MyouvUJ"},"source":["### Gaussian Blur"]},{"cell_type":"markdown","metadata":{"id":"WPtpD_YIuvUJ"},"source":["The `cv2.GaussianBlur()` function in Python is a part of the OpenCV library, widely used for image processing and computer vision tasks. This function applies Gaussian blurring to an input image (source image) and returns the result in the destination image (if provided) [Bradski, 2000, OpenCV Developers, 2023].\n","\n","This function is used to generate a Gaussian kernel, often used in image processing for tasks like blurring and smoothing. Let's break down the documentation and its parameters academically:\n","\n","- `ksize`: This parameter represents the aperture size of the Gaussian kernel. It should be an odd, positive integer. In mathematical terms, it must satisfy the condition `(ksize % 2) == 1`. The kernel size determines the size of the kernel matrix.\n","\n","- `sigma`: The Gaussian standard deviation. This parameter controls the spread or \"width\" of the Gaussian distribution. If it is non-positive (e.g., zero or negative), the function computes `sigma` from `ksize` using the formula `sigma = 0.3 * ((ksize - 1) * 0.5 - 1) + 0.8`. This calculation ensures that a reasonable standard deviation is chosen based on the kernel size.\n","\n","- `ktype`: This parameter specifies the type of filter coefficients. It can take one of two values: `cv2.CV_32F` for 32-bit floating-point coefficients or `cv2.CV_64F` for 64-bit floating-point coefficients. The choice of data type affects the precision of the filter coefficients.\n","\n","The function `cv2.getGaussianKernel` calculates and returns a `ksize x 1` matrix (column vector) containing the Gaussian filter coefficients. The coefficients are computed using the Gaussian function formula:\n","\n","\\begin{equation}G_i = \\alpha \\cdot \\exp\\left({-\\frac{(i - \\frac{{\\text{ksize}} - 1}{2})^2}{2 \\cdot \\text{sigma}^2}}\\right)\n","\\end{equation}\n","\n","Where:\n","- $i$ ranges from 0 to `ksize - 1`.\n","- $\\alpha$ is a scale factor chosen so that the sum of all Gaussian filter coefficients equals 1: $\\sum_i G_i = 1$.\n","\n","The generated Gaussian kernel is typically used in image filtering operations to apply Gaussian smoothing to an image. Gaussian smoothing helps reduce noise and blur the image in a controlled manner. The kernel can be passed to functions like `sepFilter2D` or `createSeparableLinearFilter`, which are designed to work with kernels efficiently. Alternatively, you can use the higher-level function `GaussianBlur` in OpenCV to apply Gaussian smoothing directly to an image.\n","\n","For more details, please see [Gaussian Blur](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=cv2.blur#gaussianblur)."]},{"cell_type":"markdown","metadata":{"id":"SJ-7HAchuvUJ"},"source":["The formula used in `cv2.getGaussianKernel` for computing Gaussian filter coefficients is a discretized version of the continuous Gaussian function. Let's explore the relationship between the two:\n","\n","1. **Continuous Gaussian Function**:\n","   - The continuous Gaussian function is a mathematical function used to describe the Gaussian probability distribution. It's defined as:\n","   \n","     \\begin{equation}G(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\end{equation}\n","\n","     - $x$ is the continuous independent variable.\n","     - $\\mu$ (mu) is the mean (average) value.\n","     - $\\sigma$ (sigma) is the standard deviation, controlling the spread or width.\n","     - $e$ is the base of the natural logarithm (approximately 2.71828).\n","     - $\\pi$ is the mathematical constant pi (approximately 3.14159).\n","\n","2. **Discretized Gaussian Kernel** (from `cv2.getGaussianKernel`):\n","   - The formula for computing $G_i$ in the discretized Gaussian kernel is as follows:\n","\n","     \\begin{equation}G_i = \\alpha \\cdot \\exp\\left(-\\frac{(i - \\frac{{\\text{ksize}} - 1}{2})^2}{2 \\cdot \\text{sigma}^2}\\right)\\end{equation}\n","\n","     - $i$ ranges from 0 to `ksize - 1`, representing discrete positions within the kernel.\n","     - $\\frac{{\\text{ksize}} - 1}{2}$ represents the center position of the kernel, ensuring symmetry.\n","     - $\\text{sigma}$ is the standard deviation, controlling the width of the Gaussian distribution.\n","     - $\\alpha$ is a scaling factor to normalize the kernel weights.\n","\n","**Relationship**:\n","   - The relationship between the two formulas lies in their underlying concept.\n","   - The continuous Gaussian function describes a smooth, continuous distribution.\n","   - The discretized Gaussian kernel is an approximation of this continuous function, suitable for use in discrete systems like digital image processing.\n","   - By discretizing the Gaussian function, we obtain a set of discrete weights (the $G_i$ values) that approximate the behavior of the continuous Gaussian distribution.\n","   - These weights are used as coefficients in a convolution operation to achieve Gaussian smoothing or blurring in digital images."]},{"cell_type":"markdown","metadata":{"id":"-bcxd_rHuvUJ"},"source":["<font color='Blue'><b>Example</b></font>:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Sjo1osauvUJ"},"outputs":[],"source":["# Create a 2x2 grid of subplots for displaying images\n","fig, ax = plt.subplots(2, 2, figsize=(9.5, 7.5))\n","ax = ax.ravel()  # Flatten the subplots for easier manipulation\n","\n","# Display the original image in the first subplot\n","_ = ax[0].imshow(Img)\n","_ = ax[0].set_title('Original Image', weight='bold')\n","\n","# Loop to display images with Gaussian blur at different kernel sizes\n","for i in range(1, 4):\n","    # Calculate the kernel size based on the loop iteration\n","    ksize_x = (2**(i-1)) * 4 + 1\n","\n","    # Apply Gaussian blur to the image and display it in the corresponding subplot\n","    _ = ax[i].imshow(cv2.GaussianBlur(src=Img, ksize=(ksize_x, ksize_x), sigmaX=0, sigmaY=0))\n","\n","    # Set the title for the subplot with information about the kernel size\n","    _ = ax[i].set_title(f'GaussianBlur (Kernel Size: {ksize_x} by {ksize_x})', weight='bold')\n","\n","# Additional settings for each subplot\n","for i in range(len(ax)):\n","    _ = ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n","    _ = ax[i].axis('off')    # Turn off axis\n","\n","_ = fig.suptitle('Various Kernel Sizes for cv2.GaussianBlur', weight='bold', fontsize=18)\n","# Ensure tight layout for better spacing\n","plt.tight_layout()"]},{"cell_type":"markdown","source":["Note that here"],"metadata":{"id":"wnGh2tM62kba"}},{"cell_type":"code","source":["import numpy as np\n","from pprint import pprint\n","\n","def gaussian_kernel_2d(ksize_x, ksize_y, sigma_x, sigma_y):\n","    kernel_x = cv2.getGaussianKernel(ksize_x, sigma_x)\n","    kernel_y = cv2.getGaussianKernel(ksize_y, sigma_y)\n","    kernel = kernel_x * kernel_y.T  # Use the outer product to create a 2D kernel\n","    return kernel\n","\n","# Example usage\n","ksize_x = 5\n","ksize_y = 5\n","sigma_x = 0\n","sigma_y = 0\n","gaussian_kernel = gaussian_kernel_2d(ksize_x, ksize_y, sigma_x, sigma_y)\n","pprint(gaussian_kernel)"],"metadata":{"id":"47m-Kk4V2jMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Img_Gauss_cv2 = cv2.GaussianBlur(src=Img, ksize=(ksize_x, ksize_x), sigmaX=0, sigmaY=0)\n","Img_Gauss_ours = cv2.filter2D(Img, -1, gaussian_kernel)\n","\n","# Display the original noisy image with noise and the filtered image side by side\n","fig, ax = ImShow(Images=[Img_Gauss_cv2, Img_Gauss_ours],\n","                 Names=['GaussianBlur cv2 with ksize = 5', 'GaussianBlur ours with ksize = 5'],\n","                 title='Blur Filter on Noisy Image')"],"metadata":{"id":"-iJX9lOZ2muY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6j7WSlonuvUL"},"source":["## Feature Detection"]},{"cell_type":"markdown","metadata":{"id":"X1QvvghBuvUL"},"source":["### Sobel Derivatives\n","\n","**Sobel Operator**\n","1. The Sobel Operator is a mathematical tool commonly used in image processing. Its primary purpose is to help us understand how rapidly the intensity of an image changes at each point. In simpler terms, it helps identify edges and details within an image [OpenCV Developers, 2023].\n","\n","2. What makes the Sobel Operator particularly useful is that it combines two fundamental image processing techniques: smoothing and differentiation [OpenCV Developers, 2023].\n","\n","**Formulation**\n","\n","Assuming we have an image, denoted as $I$:\n","\n","1. **Derivative Calculation:**\n","   - To begin, we want to find out how the image changes in the horizontal (left to right) direction. This is done by applying a mathematical operation called convolution between the image $I$ and a specific pattern called the \"kernel.\" The kernel used for horizontal changes is denoted as $G_x$. When we have a 3x3 kernel, it looks like this:\n","\n","   \\begin{equation} G_x = \\begin{bmatrix} -1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1 \\end{bmatrix} \\end{equation}\n","\n","   - In parallel, we also want to know how the image changes vertically (from top to bottom). To do this, we apply another convolution with a different kernel called $G_y$, which, with a 3x3 size, appears as:\n","\n","   \\begin{equation} G_y = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +2 & +1 \\end{bmatrix} \\end{equation}\n","\n","   These convolution operations reveal how the intensity of the image varies in both horizontal and vertical directions.\n","\n","2. **Gradient Approximation:**\n","   - Now that we have these two sets of information (horizontal and vertical changes), we want to combine them to find an overall measure of change at each point in the image. This is typically done using a method called the \"gradient\".\n","\n","   - The gradient at each point is calculated as [OpenCV Developers, 2023]:\n","\n","   \\begin{equation} G = \\sqrt{ G_{x}^{2} + G_{y}^{2} } \\end{equation}\n","\n","   This equation computes the magnitude of change by taking the square root of the sum of squared changes in both directions. It provides a measure of how \"edgy\" or \"smooth\" the image is at each point [OpenCV Developers, 2023].\n","\n","   - Alternatively, for simplicity and computational efficiency, we can use the \"L1 Norm\" to approximate the gradient:\n","\n","   \\begin{equation} G = |G_{x}| + |G_{y}| \\end{equation}\n","\n","   This version considers the absolute values of the changes in both directions and can still be useful in edge detection.\n","   \n","\n","**Kernel Size and Accuracy**\n","\n","When using a small kernel size, such as 3x3, the Sobel operator may produce noticeable inaccuracies in edge detection. This is because the Sobel operator is, fundamentally, an approximation of the derivative of an image [OpenCV Developers, 2023].\n","\n","**Improved Accuracy with Scharr Operator**\n","\n","To address this issue and achieve higher accuracy, OpenCV provides the Scharr() function. The Scharr operator is not only faster but also more accurate than the standard Sobel function, especially when dealing with small kernel sizes [OpenCV Developers, 2023].\n","\n","**Scharr Kernels**\n","\n","The Scharr operator implements the following kernels for gradient calculation:\n","\n","- **Horizontal Changes ($G_x$):**\n","\\begin{equation}\n","G_{x} = \\begin{bmatrix} -3 & 0 & +3 \\\\ -10 & 0 & +10 \\\\ -3 & 0 & +3 \\end{bmatrix}\n","\\end{equation}\n","\n","- **Vertical Changes ($G_y$):**\n","\\begin{equation}\n","G_{y} = \\begin{bmatrix} -3 & -10 & -3 \\\\ 0 & 0 & 0 \\\\ +3 & +10 & +3 \\end{bmatrix}\n","\\end{equation}\n","\n","These Scharr kernels are designed to provide a more accurate estimation of gradient changes, especially in scenarios where fine details and small features need to be detected. They are particularly useful when working with kernel sizes as small as 3x3, where the standard Sobel operator might fall short in terms of accuracy.\n","\n","For more in-depth information and practical examples on Sobel and Scharr operators, you can explore the [Sobel Derivatives](https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.html?highlight=scharr) documentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ET_o2G2AuvUL"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from skimage import io\n","import matplotlib.pyplot as plt\n","\n","# Load and convert the image to grayscale\n","img_url = r'https://conted.ucalgary.ca/maincampus/maincampus.jpg'\n","img = cv2.cvtColor(io.imread(img_url), cv2.COLOR_BGR2GRAY)\n","\n","# Calculate the gradient using the Sobel operator\n","gradient_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n","gradient_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n","\n","# Calculate the magnitude and direction of the gradient\n","gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n","gradient_direction = np.arctan2(gradient_y, gradient_x)\n","\n","# Create a 3x2 grid of subplots for displaying images\n","fig, ax = plt.subplots(3, 2, figsize=(9.5, 10))\n","ax = ax.ravel()\n","fig.delaxes(ax[-1])  # Remove the last subplot\n","\n","# Plot the gradient components\n","images = [img, gradient_x, gradient_y, gradient_direction, gradient_magnitude]\n","titles = ['Original Image (Grayscale)', 'Gradient X', 'Gradient Y', 'Gradient Direction', 'Gradient Magnitude']\n","\n","for i, (image, title) in enumerate(zip(images, titles)):\n","    ax[i].imshow(cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U), cmap='gray')\n","    ax[i].set_title(title, weight='bold')\n","\n","    # Additional settings for each subplot\n","    ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n","    ax[i].axis('off')    # Turn off axis\n","\n","_ = fig.suptitle('Sobel Derivatives', weight='bold', fontsize=18)\n","# Ensure tight layout for better spacing\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1ty1N8MuvUP"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from skimage import io\n","import matplotlib.pyplot as plt\n","\n","# Load and convert the image to grayscale\n","img_url = r'https://conted.ucalgary.ca/maincampus/maincampus.jpg'\n","img = cv2.cvtColor(io.imread(img_url), cv2.COLOR_BGR2GRAY)\n","\n","# Calculate the gradient using the Sobel operator\n","gradient_x = cv2.Scharr(img, cv2.CV_64F, 1, 0)\n","gradient_y = cv2.Scharr(img, cv2.CV_64F, 0, 1)\n","\n","# Calculate the magnitude and direction of the gradient\n","gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n","gradient_direction = np.arctan2(gradient_y, gradient_x)\n","\n","# Create a 3x2 grid of subplots for displaying images\n","fig, ax = plt.subplots(3, 2, figsize=(9.5, 10))\n","ax = ax.ravel()\n","fig.delaxes(ax[-1])  # Remove the last subplot\n","\n","# Plot the gradient components\n","images = [img, gradient_x, gradient_y, gradient_direction, gradient_magnitude]\n","titles = ['Original Image (Grayscale)', 'Gradient X', 'Gradient Y', 'Gradient Direction', 'Gradient Magnitude']\n","\n","for i, (image, title) in enumerate(zip(images, titles)):\n","    ax[i].imshow(cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U), cmap='gray')\n","    ax[i].set_title(title, weight='bold')\n","\n","    # Additional settings for each subplot\n","    ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n","    ax[i].axis('off')    # Turn off axis\n","\n","_ = fig.suptitle('Scharr Derivatives', weight='bold', fontsize=18)\n","# Ensure tight layout for better spacing\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"v0SlKoWuuvUP"},"source":["### Canny Edge Detection Algorithm\n","\n","Canny Edge Detection is a widely employed algorithm for detecting edges in images, introduced by John F. Canny [Canny, 1986]. This multi-stage algorithm involves the following key steps:\n","\n","1. **Noise Reduction**: To mitigate the impact of image noise, a 5x5 Gaussian filter is applied to the image. This step aims to enhance the overall quality of the image by reducing noise artifacts [OpenCV Developers, 2023].\n","\n","2. **Intensity Gradient Calculation**: Following noise reduction, the smoothened image undergoes gradient calculations in both horizontal ($G_x$) and vertical ($G_y$) directions. These gradients are used to determine the edge gradient magnitude ($G$) and direction ($\\theta$) for each pixel [OpenCV Developers, 2023]:\n","\n","   \\begin{align}\n","   G &= \\sqrt{G_x^2 + G_y^2}\\\\\n","   \\theta &= \\tan^{-1} \\left(\\frac{G_y}{G_x}\\right)\n","   \\end{align}\n","\n","   It's essential to note that the gradient direction is always perpendicular to the edges and is quantized to one of four angles, representing vertical, horizontal, and two diagonal directions [OpenCV Developers, 2023].\n","\n","3. **Non-maximum Suppression**: In this stage, a comprehensive scan of the image is conducted to eliminate extraneous pixels that do not constitute edges. For each pixel, a check is performed to ascertain if it is a local maximum within its neighborhood along the gradient direction. If a pixel qualifies as a local maximum, it is retained for subsequent stages; otherwise, it is suppressed (set to zero) [OpenCV Developers, 2023].\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/nms.jpg\" alt=\"picture\" width=\"700\">\n","</center>\n","\n","\n","Point A resides on the edge in the vertical direction, and the gradient direction aligns perpendicularly to this edge. Points B and C lie along the gradient directions. Point A is subject to evaluation by comparing it to points B and C to determine if it qualifies as a local maximum. If it meets this criterion, it proceeds to the subsequent stage of processing; otherwise, it undergoes suppression and is assigned a value of zero. Image courtesy of [OpenCV Developers, 2023].\n","\n","\n","\n","4. **Hysteresis Thresholding**: This stage is crucial for distinguishing genuine edges from non-edges. It relies on two threshold values, namely, minVal and maxVal. Pixels with intensity gradients exceeding maxVal are unequivocally identified as edges, while those falling below minVal are unequivocally classified as non-edges and discarded. Pixels falling between these two thresholds are assessed based on their connectivity to \"sure-edge\" pixels. If they are connected to such pixels, they are deemed part of the edges; otherwise, they are also discarded [OpenCV Developers, 2023].\n","\n","\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/hysteresis.jpg\" alt=\"picture\" width=\"500\">\n","</center>\n","\n","\n","Edge A surpasses the threshold maxVal, categorizing it as a \"sure-edge.\" Conversely, while edge C falls below maxVal, its connectivity to edge A validates it as a legitimate edge, resulting in the formation of the complete curve. In contrast, edge B, despite exceeding minVal and residing within the same region as edge C, lacks connectivity to any \"sure-edge\" and is consequently discarded. Consequently, the precise selection of minVal and maxVal is of paramount importance in achieving accurate results. Image courtesy of [OpenCV Developers, 2023].\n","\n","\n","It's imperative to carefully select minVal and maxVal to obtain the desired results and effectively eliminate small pixel noise, as the algorithm assumes that edges correspond to elongated lines [OpenCV Developers, 2023]."]},{"cell_type":"markdown","metadata":{"id":"TcMNo5QhuvUP"},"source":["### Canny Edge Detection in OpenCV\n","\n","OpenCV conveniently encapsulates the Canny Edge Detection algorithm within a single function: `cv.Canny()`. Let's delve into its usage and parameters.\n","\n","- **Input Image**: The first argument is the input image on which edge detection is applied.\n","\n","- **Threshold Values**: The second and third arguments, denoted as minVal and maxVal respectively, establish the lower and upper thresholds for the edge detection process.\n","\n","- **Aperture Size**: The fourth argument, aperture_size, signifies the size of the Sobel kernel employed for computing image gradients. By default, it assumes a size of 3.\n","\n","- **L2 Gradient**: The last argument, L2gradient, is a Boolean parameter that specifies the equation for calculating gradient magnitude. When set to True, it employs the more accurate equation discussed earlier: $Edge\\_Gradient \\; (G) = \\sqrt{G_x^2 + G_y^2}$. Conversely, when set to False, it employs the alternative function: $Edge\\_Gradient \\; (G) = |G_x| + |G_y|$.\n","\n","### `cv2.Canny` Function\n","\n","```python\n","cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) → edges\n","```\n","\n","Parameters:\n","- `image`: This is the input image on which the Canny edge detection is to be applied. It should be a single-channel 8-bit grayscale image.\n","\n","- `threshold1`: The lower threshold value. It's an integer and is used to identify weaker edges. Pixels with gradient magnitudes below this threshold are discarded as non-edges.\n","\n","- `threshold2`: The higher threshold value. It's also an integer and is used to identify stronger edges. Pixels with gradient magnitudes above this threshold are marked as strong edges.\n","\n","- `edges` (optional): This is an output image that will store the edges found by the Canny algorithm. It should have the same size as the input image. This parameter is optional, and if not provided, the function returns the edge map directly.\n","\n","- `apertureSize` (optional): This is the size of the Sobel kernel used for gradient calculation. It's an integer, and typical values are 3 (default) or 5. A larger aperture size can reduce noise, but it may also reduce sensitivity to small details in the image.\n","\n","- `L2gradient` (optional): A Boolean parameter (True or False). If set to True, the function uses the $L_2$ gradient magnitude for gradient calculations. If set to False (default), it uses the $L_1$ gradient magnitude. Using $L_2$ gradient can result in slightly more accurate edge detection.\n","\n","Return Value:\n","- `edges`: This is the output edge map, either provided as the `edges` parameter or returned by the function. It's a binary image where edge pixels are marked with white (255) and non-edge pixels with black (0).\n","\n","For further details, refer to the [OpenCV documentation on Canny Edge Detection](https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html)."]},{"cell_type":"markdown","metadata":{"id":"eBEcdBRcuvUP"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhdQhXlVuvUP"},"outputs":[],"source":["# Import necessary libraries\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_sample_images\n","from skimage import io\n","import cv2\n","\n","# Load sample images\n","sample_images = load_sample_images()['images']\n","sample_names = [x.split(\"/\")[-1].replace('.jpg', '').title() for x in load_sample_images()['filenames']]\n","\n","# Load the custom image (UofC)\n","uofc_img_url = r'https://conted.ucalgary.ca/maincampus/maincampus.jpg'\n","uofc_img = io.imread(uofc_img_url)\n","sample_images.append(uofc_img)\n","sample_names.append('UofC')\n","\n","# Create a 2x2 grid of subplots for displaying images\n","fig, ax = plt.subplots(len(sample_images), 2, figsize=(9.5, 10))\n","ax = ax.ravel()  # Flatten the subplots for easier manipulation\n","\n","# Loop to display original images and their edges\n","for i, img in enumerate(sample_images):\n","    # Display the original image in the left subplot\n","    ax[i*2].imshow(img, cmap='gray')\n","    ax[i*2].set_title(f'Original Image - {sample_names[i]}', weight='bold')\n","\n","    # the original image in grayscale\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    edge_img = cv2.Canny(img, threshold1 = 100, threshold2 = 200)\n","\n","    # Display the edge-detected image in the right subplot\n","    ax[i*2+1].imshow(edge_img, cmap='gray')\n","    ax[i*2+1].set_title(f'Image Edges - {sample_names[i]}', weight='bold')\n","\n","# Additional settings for each subplot\n","for i in range(len(ax)):\n","    ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n","    ax[i].axis('off')    # Turn off axis\n","\n","plt.tight_layout()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}