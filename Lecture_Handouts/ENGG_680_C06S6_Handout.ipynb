{"cells":[{"cell_type":"markdown","id":"a9e2e61f","metadata":{"id":"a9e2e61f"},"source":["# Aggregation and Grouping in Pandas\n","\n","In data analysis and manipulation, the concepts of aggregation and grouping play a crucial role, allowing us to derive insights from complex datasets. This section will delve deeper into the fundamental concepts of aggregation and grouping in the context of pandas, a powerful Python library for data manipulation and analysis.\n","\n","## Grouping Data with `groupby()`\n","Grouping data involves categorizing and splitting a dataset into smaller subsets based on specific criteria. The `groupby()` function in pandas is a fundamental tool for accomplishing this task. It allows us to group a DataFrame based on one or more columns, enabling subsequent analysis and computation within these groups [McKinney, 2022, Pandas Developers, 2023].\n","\n","### Basic Syntax\n","The basic syntax for using the `groupby()` function is as follows {cite:p}`PandasDocumentation`:\n","```python\n","grouped = df.groupby('column_name')\n","```\n","\n","Full syntax can be found [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)."]},{"cell_type":"markdown","id":"b2b70b44","metadata":{"id":"b2b70b44"},"source":["<font color='Blue'><b>Example</b></font> This dataset records meteorological observations for the \"UNIVERSITY OF CALGARY\" weather station. It was obtained from the source https://climate.weather.gc.ca/ and includes the following columns:\n","\n","1. **Station Name:** The name of the weather station, which is \"UNIVERSITY OF CALGARY\" in this case.\n","\n","2. **Date/Time:** The date and time of the observation in the format MM/DD/YYYY.\n","\n","3. **Year:** The year of the observation, extracted from the Date/Time column.\n","\n","4. **Month:** The month of the observation, extracted from the Date/Time column.\n","\n","5. **Day:** The day of the observation, extracted from the Date/Time column.\n","\n","6. **Max Temp (°C):** The maximum temperature recorded on that date in degrees Celsius.\n","\n","7. **Min Temp (°C):** The minimum temperature recorded on that date in degrees Celsius.\n","\n","8. **Mean Temp (°C):** The mean temperature recorded on that date in degrees Celsius, typically calculated as the average of the maximum and minimum temperatures.\n","\n","9. **Total Rain (mm):** The total amount of rainfall in millimeters on that date.\n","\n","10. **Total Snow (cm):** The total amount of snowfall in centimeters on that date.\n","\n","11. **Total Precip (mm):** The cumulative total of precipitation, which combines rain and snow, in millimeters on that date."]},{"cell_type":"code","execution_count":null,"id":"9f3019c6","metadata":{"id":"9f3019c6"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('https://raw.githubusercontent.com/HatefDastour/ENGG_680/main/Datasets/UofC_Daily_1990_Q1Q2.csv')\n","\n","# Display the first few rows of the DataFrame\n","display(df.tail())\n","\n","# Grouping by 'Month'\n","grouped = df.groupby('Month')\n","print('grouped would be an object as follows:')\n","print(grouped)"]},{"cell_type":"markdown","id":"fceeb414","metadata":{"id":"fceeb414"},"source":["## Aggregation: Extracting Insights from Groups\n","\n","Once you've successfully grouped your data using the `groupby()` function, the next step is to harness the power of aggregation. Aggregation involves summarizing and extracting meaningful information from the grouped data by applying various functions to each group. This process unveils hidden patterns, trends, and characteristics within your dataset.\n","\n","Pandas offers a multitude of aggregation functions that allow you to compute summary statistics and insights for each group. These functions include [McKinney, 2022, Pandas Developers, 2023]:\n","- **Mean**: Calculates the average value of a specific column within each group.\n","- **Sum**: Computes the total sum of values in a column for each group.\n","- **Count**: Determines the number of non-null values within a column for each group.\n","- **Max**: Identifies the maximum value within a column for each group.\n","- **Min**: Finds the minimum value within a column for each group.\n","- ...and many more."]},{"cell_type":"code","execution_count":null,"id":"f57d0eae","metadata":{"scrolled":false,"id":"f57d0eae"},"outputs":[],"source":["def Line(n=40):\n","    print(n * \"_\")\n","\n","# Applying aggregation functions on the groups\n","\n","# Calculating the mean of 'Value' for each group\n","average_values = grouped['Max Temp (°C)'].mean().round(2)\n","print(\"Average Values:\")\n","print(average_values)\n","Line()\n","\n","# Calculating the sum of 'Value' for each group\n","sum_values = grouped['Max Temp (°C)'].sum().round(2)\n","print(\"Sum Values:\")\n","print(sum_values)\n","Line()\n","\n","# Counting the number of occurrences in each group\n","count_values = grouped['Max Temp (°C)'].count().round(2)\n","print(\"Count Values:\")\n","print(count_values)\n","Line()\n","\n","# Finding the maximum value in each group\n","max_value = grouped['Max Temp (°C)'].max().round(2)\n","print(\"Max Values:\")\n","print(max_value)\n","Line()\n","\n","# Finding the minimum value in each group\n","min_value = grouped['Max Temp (°C)'].min().round(2)\n","print(\"Min Values:\")\n","print(min_value)\n","Line()"]},{"cell_type":"markdown","id":"695c402d","metadata":{"id":"695c402d"},"source":["## Multiple aggregations\n","\n","You can apply multiple aggregation functions simultaneously using the `agg()` method."]},{"cell_type":"markdown","id":"4cf66185","metadata":{"id":"4cf66185"},"source":["<font color='Blue'><b>Example - Exploring Store Sales Patterns:</b></font> Imagine you're analyzing sales data for a small boutique store. The store sells products from two categories, 'A' and 'B'. You want to understand how the sales values for these categories differ.\n","\n","You start by generating a random dataset using numpy and pandas to simulate the store's sales records. You set a random seed for reproducibility and create 100 rows of data. Each row has a 'Category' column with either 'A' or 'B' values and a 'Value' column with random sales amounts between 1 and 100."]},{"cell_type":"code","execution_count":null,"id":"d7f51994","metadata":{"id":"d7f51994"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Set the random seed for reproducibility\n","rng = np.random.default_rng(42)\n","\n","# Define the number of rows in the DataFrame\n","num_rows = 100\n","\n","# Generate random alphabet column with only 'A' and 'B'\n","random_alphabet = [rng.choice(['A', 'B']) for _ in range(num_rows)]\n","\n","# Generate random numeric column\n","random_numeric = rng.integers(1, 101, size=num_rows)\n","\n","# Create a Pandas DataFrame\n","data = {'Category': random_alphabet, 'Value': random_numeric}\n","df = pd.DataFrame(data)\n","\n","# Display the first few rows of the DataFrame\n","display(df.head())"]},{"cell_type":"code","execution_count":null,"id":"547e8dfd","metadata":{"id":"547e8dfd"},"outputs":[],"source":["# Grouping by 'Category'\n","grouped = df.groupby('Category')\n","\n","#  Applying multiple aggregation functions\n","agg_functions = {'Value': ['mean', 'sum', 'count', 'max', 'min']}\n","result = grouped.agg(agg_functions)\n","# or simply result = grouped.agg({'Value': ['mean', 'sum', 'count', 'max', 'min']})\n","display(result)"]},{"cell_type":"markdown","id":"9cb7dc8b","metadata":{"id":"9cb7dc8b"},"source":["## Grouping by multiple columns\n","Suppose we have a dataset containing sales data for different products in different regions. We want to group the data by both \"Product\" and \"Region\" to analyze the total sales and average price for each combination.\n"]},{"cell_type":"code","execution_count":null,"id":"b366f55f","metadata":{"id":"b366f55f"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Set the random seed for reproducibility\n","rng = np.random.default_rng(42)\n","\n","# Define the number of rows in the DataFrame\n","num_rows = 100\n","\n","# Generate random data using NumPy functions directly\n","data = {\n","    'Product': rng.choice(['A', 'B'], num_rows),\n","    'Region': rng.choice(['North', 'South'], num_rows),\n","    'Sales': rng.integers(100, 201, size=num_rows),\n","    'Price': rng.integers(10, 23, size=num_rows)\n","}\n","\n","# Create a Pandas DataFrame from the dictionary\n","df = pd.DataFrame(data)\n","\n","# Display the resulting DataFrame\n","display(df.head())\n","\n","# Grouping by both \"Product\" and \"Region\"\n","result = df.groupby(['Product', 'Region']).agg({'Sales': 'sum', 'Price': 'mean'})\n","\n","# Display the result\n","display(result)"]},{"cell_type":"markdown","source":["## Grouping and Resampling Time Series Data\n","\n","### `resample` Function for Time Series Analysis\n","\n","The `resample` function within pandas is a versatile and dynamic tool designed explicitly for managing time series data. It extends the capability to modify the frequency of your time-dependent data and simultaneously carry out a multitude of aggregation operations on the grouped data. The essence of the `resample` function can be succinctly encapsulated as follows [Pandas Developers, 2023]:\n","\n","When applied to pandas DataFrames or Series with a datetime index, the `resample` function's primary purpose is to partition time series data into distinct time intervals (such as days, months, years) while offering the flexibility to employ aggregation functions within each interval. The general syntax of utilization stands as:\n","\n","```python\n","new_resampled_object = df.resample(rule)\n","```\n","\n","In this context, `rule` symbolizes a string that defines the desired resampling frequency, such as `'D'` for daily, `'M'` for monthly, `'A'` for annually, and so forth.\n","\n","The true power of the `resample` function lies in its inherent adaptability, enabling a seamless exploration of trends, patterns, and aggregated insights across various time intervals.\n","\n","You can find a comprehensive description by following this [link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html).\n","\n","<font color='Blue'><b>Example:</b></font> Consider our initial illustration involving climate data from the University of Calgary station for the 1st half of the year 1990."],"metadata":{"id":"z-eDrj_Nug_z"},"id":"z-eDrj_Nug_z"},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('https://raw.githubusercontent.com/HatefDastour/ENGG_680/main/Datasets/UofC_Daily_1990_Q1Q2.csv',\n","                parse_dates = ['Date/Time'])\n","df = df.set_index('Date/Time')\n","\n","# Grouping by month and calculating the sum of sales and revenue for each group\n","result = df.resample('MS').agg({'Mean Temp (°C)': 'mean'})\n","\n","display(result)"],"metadata":{"id":"zfcloEqlugNr"},"id":"zfcloEqlugNr","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pandas pivot\n","\n","The `pandas.DataFrame.pivot` method is a powerful feature in the pandas library for reshaping data in a DataFrame. It allows you to transform your data from a long format (where data is stored in rows) to a wide format (where data is stored in columns) or vice versa. This can be particularly useful when you need to analyze or visualize your data in a different structure.\n","\n","**Syntax:**\n","```python\n","DataFrame.pivot(index=None, columns=None, values=None)\n","```\n","\n","- `index`: This parameter specifies the column whose unique values will become the new index (row labels) of the pivoted DataFrame. It can be a column name or a list of column names.\n","\n","- `columns`: This parameter specifies the column whose unique values will become the new column headers of the pivoted DataFrame. It can be a column name or a list of column names.\n","\n","- `values`: This parameter specifies the column(s) containing the data to populate the pivoted DataFrame. It can be a column name or a list of column names. If not provided, all remaining columns not used as `index` or `columns` will be used.\n","\n","We can see the full syntax [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html)."],"metadata":{"id":"6UjziZNHlW9I"},"id":"6UjziZNHlW9I"},{"cell_type":"markdown","source":["<font color='Blue'><b>Example:</b></font> We can use `pivot` to transform data from a long format (e.g., for time-series data) to a wide format, making it easier to analyze."],"metadata":{"id":"jdLI9izplY6f"},"id":"jdLI9izplY6f"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Create a DataFrame with air quality data\n","# This dataset is a fictional dataset:\n","air_quality_data = pd.DataFrame({\n","    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n","    'Pollutant': ['CO', 'NO2', 'CO', 'NO2'],\n","    'Value': [2.5, 20.1, 2.7, 22.3]\n","})\n","\n","# Print the original air quality data DataFrame\n","print(\"Original Air Quality Data:\")\n","display(air_quality_data)\n","\n","# Pivot the air quality data to a wide format\n","pivoted_air_quality = air_quality_data.pivot(index='Date', columns='Pollutant', values='Value')\n","\n","# Print the pivoted air quality data\n","print(\"\\nPivoted Air Quality Data (Wide Format):\")\n","display(pivoted_air_quality)"],"metadata":{"id":"9fm45WLhlXTW"},"id":"9fm45WLhlXTW","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `pandas.melt` function is a powerful tool for converting a DataFrame from wide format to long format, making it easier to work with certain types of data. It essentially \"unpivots\" a DataFrame by melting columns into rows. This can be particularly useful when you want to analyze or visualize data that is initially organized with column headers representing different variables.\n","\n","**Syntax:**\n","```python\n","pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n","```\n","\n","- `frame`: This parameter specifies the DataFrame you want to melt.\n","\n","- `id_vars`: This parameter specifies the column(s) that should remain as identifier variables (columns that won't be melted). It can be a column name or a list of column names.\n","\n","- `value_vars`: This parameter specifies the column(s) that should be melted (unpivoted). If not specified, all columns not listed in `id_vars` will be melted.\n","\n","- `var_name`: This parameter specifies the name of the new column that will store the variable names (from the melted columns).\n","\n","- `value_name`: This parameter specifies the name of the new column that will store the values (from the melted columns).\n","\n","- `col_level`: This parameter is used when working with MultiIndex columns. It specifies which level of the column index should be melted.\n","\n","We can see the full syntax [here](https://pandas.pydata.org/docs/reference/api/pandas.melt.html).\n","\n","\n","<font color='Blue'><b>Example:</b></font> Let's apply the `melt` function to the previous air quality data example:"],"metadata":{"id":"8xE2tfCJlgRB"},"id":"8xE2tfCJlgRB"},{"cell_type":"code","source":["# Reset the index to convert 'Date' back to a regular column\n","pivoted_air_quality.reset_index(inplace=True)\n","display(pivoted_air_quality)\n","\n","# Use the melt function to transform the data to long format\n","melted_air_quality = pd.melt(pivoted_air_quality, id_vars=['Date'], value_vars=['CO', 'NO2'],\n","                              var_name='Pollutant', value_name='Value')\n","\n","# Print the melted air quality data in long format\n","print(\"Melted Air Quality Data (Long Format):\")\n","display(melted_air_quality)"],"metadata":{"id":"sLzqbnHvlZ1Z"},"id":"sLzqbnHvlZ1Z","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}