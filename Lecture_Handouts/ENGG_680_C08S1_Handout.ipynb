{"cells":[{"cell_type":"markdown","metadata":{"id":"dey2j_8_ogHW"},"source":["# Getting Started with OpenCV\n","\n","\n","OpenCV (Open Source Computer Vision) is a widely acclaimed open-source library that forms the backbone of many computer vision applications. With a rich history dating back to its inception in 1999, OpenCV has evolved into a versatile toolkit that empowers developers to create innovative solutions in the field of image and video analysis. Released under a permissive BSD license, OpenCV has garnered a strong community of researchers, engineers, and enthusiasts who contribute to its growth and enhancement [Bradski, 2000, OpenCV Developers, 2023.\n","\n","CV2, often referred to as \"opencv-python,\" is the Python wrapper for the OpenCV library. This wrapper brings the power of OpenCV's vast functionality to the Python programming ecosystem, making it accessible and convenient for Python developers. With CV2, you can perform a wide range of tasks, including image processing, feature extraction, object detection, video analysis, and more, using the intuitive and expressive syntax of Python.\n","\n","CV2's integration with Python has contributed to its popularity and ubiquity in the field of computer vision. It offers a comprehensive suite of functions and tools that enable users to manipulate, analyze, and interpret visual data effortlessly. From simple tasks like image resizing and filtering to complex tasks such as building deep learning models for image recognition, CV2 provides the necessary building blocks."]},{"cell_type":"markdown","metadata":{"id":"QTb0J3U6ogHX"},"source":["## Sample Images\n","\n","In this section, we employ `Lunenburg.jpg` and `Varenna.jpg` from my personal image library. Both images were adjusted to a size of 2000 by 1500 to facilitate more straightforward calculations.\n","\n","* [Lunenburg](https://en.wikipedia.org/wiki/Lunenburg,_Nova_Scotia) (a town in Nova Scotia, Canada) is known for its well-preserved colonial architecture and UNESCO World Heritage status.\n","\n","* [Varenna](https://en.wikipedia.org/wiki/Varenna) features the picturesque village of Varenna on the shores of Lake Como, Italy, celebrated for its charming waterfront and stunning natural beauty."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMH_FzoxogHX"},"outputs":[],"source":["from skimage import io\n","\n","Images = []\n","# Load an image from a URL\n","Names = ['Lunenburg', 'Varenna']\n","Urls = [f'https://raw.githubusercontent.com/HatefDastour/ENGG_680/main/Files/{name}.jpg' for name in Names]\n","Images = [io.imread(x) for x in Urls]"]},{"cell_type":"markdown","metadata":{"id":"akVMHLuLogHY"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chFcxJVrogHY"},"outputs":[],"source":["# Import necessary libraries\n","import matplotlib.pyplot as plt  # Import the plotting library\n","\n","# Define a function to display images with titles and optional settings\n","def ImShow(Images, Names, title='Images', grayscale=False, figsize=(9.5, 4.5)):\n","    # Create a figure with two subplots\n","    fig, ax = plt.subplots(1, 2, figsize= figsize)  # Create a figure with 1 row and 2 columns of subplots\n","    ax = ax.ravel()  # Flatten the subplots for easier manipulation\n","\n","    # Iterate over the first two images\n","    for i in range(2):\n","        # Display the image in grayscale if grayscale is True, otherwise in color\n","        ax[i].imshow(Images[i], cmap='gray' if grayscale else None)\n","        ax[i].set_aspect(1)  # Set aspect ratio to 1 (square aspect)\n","        ax[i].axis('off')  # Turn off axis\n","        ax[i].set_title(Names[i], weight='bold')  # Set image title with bold font\n","\n","    if title:\n","        # Set main title if provided\n","        fig.suptitle(title, weight='bold', fontsize=18)\n","\n","    plt.tight_layout()  # Adjust layout for better spacing\n","\n","    return fig, ax\n","\n","# Display the original images\n","_, _ = ImShow(Images, Names, title='Original Images')  # Call the ImShow function to display images"]},{"cell_type":"markdown","metadata":{"id":"dCBPw7rMogHZ"},"source":["## Accessing and Manipulating Pixel Values in Images\n","\n","To gain precise control over pixel values within an image, we leverage the versatile `split` function [Bradski, 2000, OpenCV Developers, 2023. This function proves invaluable in dissecting the intricate tapestry of color channels present within an image.\n","\n","In the digital imaging realm, each channel corresponds to a distinct color component. In the ubiquitous RGB color model, we encounter the vibrant Red, Green, and Blue channels. Alternatively, the CMYK model introduces Cyan, Magenta, Yellow, and Black channels. These models, alongside others, collectively govern an image's appearance through their distinctive channels.\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/CMYK_RGB.jpg\" alt=\"picture\" width=\"500\">\n","</center>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUJAZFrbogHZ"},"outputs":[],"source":["import cv2\n","from sklearn.datasets import load_sample_image\n","\n","# Load an example image\n","Img = load_sample_image('flower.jpg')\n","\n","# Split the channels of the first image in the 'Images' dataset\n","B, G, R = cv2.split(Img)"]},{"cell_type":"markdown","metadata":{"id":"DmAbsqciogHZ"},"source":["The following line of code utilizes the `cv2.split()` function to split the channels of the first image in the 'Images' dataset. This function separates the image into its individual color channels, where `B` corresponds to the Blue channel, `G` to the Green channel, and `R` to the Red channel. These channels represent the components that collectively create the image's color when combined.\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/CV2_BGR.png\" alt=\"picture\" width=\"700\">\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"9O3N5VaVogHZ"},"source":["Alternatively, we can access the red, green, and blue channels of `Img` using the indexing syntax `Img[:,:,0]`, `Img[:,:,1]`, and `Img[:,:,2]`. This concise notation allows direct access to each color channel within the image, where the indices 0, 1, and 2 correspond to the red, green, and blue channels respectively. This indexing approach provides a convenient and efficient way to work with individual color channels, enabling focused manipulation and analysis of the image's color components.\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/HatefDastour/hatefdastour.github.io/master/_notes/Introduction_to_Digital_Engineering/_images/RGB_bands.png\" alt=\"picture\" width=\"420\">\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"CGExmX1cogHZ"},"source":["***\n","<font color='Red'><b>Remark:</b></font> This order might seem counterintuitive when compared to the RGB order, but it is used for compatibility with certain image processing algorithms and the way images are stored in memory in the BGR (Blue, Green, Red) format.\n","***"]},{"cell_type":"markdown","metadata":{"id":"dDj2ab5UogHZ"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDL9ML1HogHZ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","for image, name in zip(Images, Names):\n","    # Create a figure with three subplots to display the color channels\n","    fig, axes = plt.subplots(1, 3, figsize=(9.5, 2.5))\n","    axes = axes.ravel()  # Flatten the subplots for easier manipulation\n","\n","    # Set the main title to the name of the image\n","    _ = fig.suptitle(name, weight='bold', fontsize=18)\n","\n","    # Iterate over the three color channels\n","    for i, (ax, channel_name) in enumerate(zip(axes, ['Red', 'Green', 'Blue'])):\n","        # Create an image with all zeros (black image) of the same size as the original image\n","        channel_image = 0 * image\n","        # Assign the values of the current color channel to the corresponding channel in the black image\n","        channel_image[:, :, i] = image[:, :, i]\n","        # Display the image for the current color channel in the subplot\n","        _ = ax.imshow(channel_image)\n","        # Set aspect ratio to 1 to avoid stretching\n","        _ = ax.set_aspect(1)\n","        # Turn off axis for cleaner visualization\n","        _ = ax.axis('off')\n","        # Add text label indicating the color channel\n","        _ = ax.text(x=0, y=0, s=channel_name, size=14,\n","                    color='White', bbox=dict(boxstyle=\"square\", ec='k', fc= channel_name))\n","\n","    plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"UuztIgoxogHa"},"source":["## Image Blending: Using the `cv2.addWeighted` Function\n","\n","Image blending is a fundamental technique in image processing that combines two images to create a new composite image. OpenCV provides the `cv2.addWeighted` function, which performs image blending based on a weighted sum of the input images and an additional constant value. Here's an explanation of the blending formula and how it works\n","[Bradski, 2000, OpenCV Developers, 2023:\n","\n","The formula for image blending using `cv2.addWeighted` is as follows:\n","\n","\\begin{equation}\n","dst = \\alpha \\cdot \\text{src1} + \\beta \\cdot \\text{src2} + \\gamma\n","\\end{equation}\n","\n","In this formula:\n","- `src1` and `src2` are the two input images to be blended.\n","- $\\alpha$ is a weighting factor that determines the influence of `src1` in the final output. It satisfies the condition $0 \\leq \\alpha \\leq 1$, meaning it controls the relative contribution of `src1` to the blended image.\n","- $\\beta = 1 - \\alpha$ represents the weighting factor for `src2`, ensuring that the sum of the weights for both images is 1.\n","- $\\gamma$ is an additional constant value that can be added to the blended result. It is an integer value that can be used for brightness adjustment.\n","\n","The `cv2.addWeighted` function in OpenCV is used for image blending, which combines two input images (`src1` and `src2`) together using a specified weight for each image. The resulting blended image is stored in the destination image (`dst`). Here's an explanation of the function signature:\n","\n","```\n","cv2.addWeighted(src1, alpha, src2, beta, gamma, dst) â†’ None\n","```\n","\n","- `src1`: The first source image, which is the primary input image for blending.\n","- `alpha`: The weight applied to the first source image (`src1`). This value determines the contribution of `src1` to the final result. A larger `alpha` value increases the influence of `src1`.\n","- `src2`: The second source image, which is the secondary input image for blending.\n","- `beta`: The weight applied to the second source image (`src2`). This value determines the contribution of `src2` to the final result. A larger `beta` value increases the influence of `src2`.\n","- `gamma`: A scalar added to the weighted sum of the two source images. This value can be used to control the brightness or contrast of the resulting image.\n","- `dst`: The destination image, where the blended image is stored. The dimensions of this image should match the dimensions of the input images.\n","\n","You can see the full description of this function [here](https://docs.opencv.org/3.4/d5/dc4/tutorial_adding_images.html).\n","\n","The `cv2.addWeighted` function performs a linear combination of the two source images (`src1` and `src2`) based on the specified weights `alpha` and `beta`, and then adds the scalar `gamma` to the resulting sum. The resulting blended image is written to the `dst` image [Bradski, 2000, OpenCV Developers, 2023.\n","\n","This function is commonly used for image fusion, creating special effects, adjusting image brightness and contrast, and other image processing tasks where combining two images with different weights is required. The `alpha` and `beta` values control the influence of each source image, and the `gamma` value can be used to control the overall brightness or contrast of the final image."]},{"cell_type":"markdown","metadata":{"id":"mo1qCPxlogHb"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6P_aUHtmogHb"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Define the size of the images\n","size = (100, 150)\n","\n","# Create two sample images with different color channels\n","Image_Red = np.zeros((size[0], size[1], 3), dtype=np.uint8)\n","Image_Red[:,:,0] = 255 * np.ones(size, dtype=np.uint8)\n","\n","Image_Green = np.zeros((size[0], size[1], 3), dtype=np.uint8)\n","Image_Green[:,:,1] = 255 * np.ones(size, dtype=np.uint8)\n","\n","Image_Blue = np.zeros((size[0], size[1], 3), dtype=np.uint8)\n","Image_Blue[:,:,2] = 255 * np.ones(size, dtype=np.uint8)\n","\n","# Create a subplot with three rows and two columns for visualization\n","fig, ax = plt.subplots(2, 3, figsize=(9.5, 5))\n","ax = ax.ravel()\n","\n","# Display the first image on the first subplot\n","_ = ax[0].imshow(Image_Red)\n","_ = ax[0].set_title('Red', weight='bold')\n","\n","_ = ax[1].imshow(Image_Green)\n","_ = ax[1].set_title('Green', weight='bold')\n","\n","_ = ax[2].imshow(Image_Blue)\n","_ = ax[2].set_title('Blue', weight='bold')\n","\n","# Blend the images and display the results\n","_ = ax[3].imshow(cv2.addWeighted(Image_Red, 0.5, Image_Green, 0.5, 0))\n","_ = ax[3].set_title('0.5 * Red + 0.5 * Green', weight='bold')\n","\n","_ = ax[4].imshow(cv2.addWeighted(Image_Red, 0.5, Image_Blue, 0.5, 0))\n","_ = ax[4].set_title('0.5 * Red + 0.5 * Blue', weight='bold')\n","\n","_ = ax[5].imshow(cv2.addWeighted(Image_Green, 0.5, Image_Blue, 0.5, 0))\n","_ = ax[5].set_title('0.5 * Green + 0.5 * Blue', weight='bold')\n","\n","# Set aspect ratio and turn off axes for all subplots\n","for i in range(len(ax)):\n","    _ = ax[i].set_aspect(1)\n","    _ = ax[i].axis('off')\n","\n","# Ensure tight layout\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"JbMYDkCeogHb"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"526vmfywogHb"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np  # Import numpy for array operations\n","import matplotlib.pyplot as plt  # Import matplotlib for visualization\n","import cv2  # Import OpenCV for image processing\n","alpha = 0.7\n","beta = 1 - alpha\n","# Method 1: Using cv2.addWeighted for Image Blending\n","# Blend two different images using weighted sums\n","# 0.7 and 0.3 are the weights applied to the first and second image, respectively\n","# 0 is the scalar value added to the resulting image\n","augmented_img_01 = cv2.addWeighted(Images[0], alpha, Images[1], beta, 0)\n","\n","# Method 2: Custom Image Blending\n","# Blend two different images using custom weighted sums\n","# We use numpy for element-wise multiplication and addition, rounding the result, and converting to 'uint8' data type\n","# This technique allows manual control of blending weights\n","augmented_img_02 = np.round((alpha * Images[0] + beta * Images[1])).astype('uint8')\n","\n","# Display the original and transformed images with titles\n","fig, ax = ImShow(Images=[augmented_img_01, augmented_img_02],\n","                 Names=['cv2.addWeighted', 'Custom Blend'],\n","                 title= f'Image Blending: {alpha:.1}*Img1 + {beta:.1}*Img2',\n","                 figsize=(9.5, 4.5))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FodJ3NXogHb"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","alpha = 0.3\n","beta = 1 - alpha\n","augmented_img_01 = cv2.addWeighted(Images[0], alpha, Images[1], beta, 0)\n","augmented_img_02 = np.round((alpha * Images[0] + beta * Images[1])).astype('uint8')\n","fig, ax = ImShow(Images=[augmented_img_01, augmented_img_02],\n","                 Names=['cv2.addWeighted', 'Custom Blend'],\n","                 title= f'Image Blending: {alpha:.1}*Img1 + {beta:.1}*Img2',\n","                 figsize=(9.5, 4.5))"]},{"cell_type":"markdown","metadata":{"id":"mdX1dbEGogHh"},"source":["## Colorspace Conversion with `cv2.cvtColor()`\n","\n","The `cv2.cvtColor()` function in the Python OpenCV library is a powerful tool for changing the colorspace of an input image or rearranging its image channels. It allows you to convert an input image (source) from one colorspace to another, based on a specified color conversion code. The resulting image can be stored in the output (destination) image, if provided, or a new image is created to hold the converted result [Bradski, 2000, OpenCV Developers, 2023.\n","\n","Here's an in-depth explanation of the parameters and the purpose of this function:\n","\n","- `src`: This parameter represents the input image (source) that you intend to convert. It should be a numpy array, effectively representing the image you want to transform.\n","\n","- `code`: The `code` parameter specifies the color conversion code or the type of transformation that defines how the input image's colors will be converted. This code is an integer value corresponding to a specific colorspace conversion or channel rearrangement. For example, `cv2.COLOR_BGR2GRAY` indicates converting from the BGR colorspace to grayscale. The available conversion codes are defined in OpenCV's documentation.\n","\n","- `dst` (optional): The `dst` parameter serves as the output image (destination) where the result of the colorspace conversion will be stored. If this parameter is not provided, a new image will be created to store the converted result.\n","\n","- `dstCn` (optional): The `dstCn` parameter specifies the number of channels in the destination image. It is used when you want to change the number of channels in the output image. If this parameter is not specified, it defaults to 0, and the number of channels is inferred based on the conversion code.\n","\n","Here's the structure of the function signature:\n","\n","```python\n","cv2.cvtColor(src, code[, dst[, dstCn]]) -> dst\n","```\n","\n","The `cv2.cvtColor()` function provides a versatile way to transform images between various colorspace representations, such as RGB, grayscale, HSV, YUV, and more. It is a fundamental operation in image processing that enables you to adapt images to different processing techniques or to analyze them from various color perspectives.\n","\n","For more detailed information and the list of available color conversion codes, you can refer to the [OpenCV documentation on `cvtColor`](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor). This function plays a crucial role in image manipulation and analysis, allowing you to work with images in different colorspaces, which is essential in various computer vision and image processing tasks."]},{"cell_type":"markdown","metadata":{"id":"09WBIA_eogHh"},"source":["### RGB to Grayscale\n","\n","To convert an image from the RGB (Red, Green, Blue) color space to grayscale, you can use the `cv2.cvtColor()` function from the OpenCV library with the appropriate color conversion code.\n","\n","\n","The `cv2.cvtColor()` function, which is part of the OpenCV library, transforms an RGB (Red, Green, Blue) image to grayscale using a well-defined mathematical formula. This operation is widely used in image processing and computer vision applications.\n","\n","The process of converting an RGB image to grayscale involves weighted averaging of the color channels (R, G, and B). The formula used by `cv2.cvtColor()` is as follows:\n","\n","```\n","Grayscale Value (G) = 0.299 * Red (R) + 0.587 * Green (G) + 0.114 * Blue (B)\n","```\n","\n","In this formula, the coefficients 0.299, 0.587, and 0.114 are specific weights assigned to the Red, Green, and Blue channels, respectively. These weights are based on the human perception of color, as the human eye is more sensitive to green and less sensitive to blue when perceiving grayscale intensity. Please see [this link](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor) for more details."]},{"cell_type":"markdown","metadata":{"id":"-p3RFRIeogHh"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"m-EshiP1ogHh"},"outputs":[],"source":["# Note that `Images` and `Names` were defined in the first example.\n","\n","# Convert RGB to Grayscale\n","gray_images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in Images]\n","# Convert each RGB image in the list `Images` to grayscale using cv2.COLOR_BGR2GRAY\n","inverted_gray_images = [cv2.bitwise_not(image) for image in gray_images]\n","# Invert the colors of the grayscale images using bitwise_not to create inverted grayscale images\n","\n","# Create titles for the images\n","gray_titles = [f'{name} (Gray)' for name in Names]\n","# Create titles for grayscale images by adding \"(Gray)\" to the original image names\n","inverted_gray_titles = [f'{name} (Inverted Gray)' for name in Names]\n","# Create titles for inverted grayscale images by adding \"(Inverted Gray)\" to the original image names\n","\n","# Note: Grayscale images only have one color channel (band).\n","# Plot the images\n","_, _ = ImShow(gray_images, gray_titles, title='RGB to Grayscale', grayscale=True)\n","# Display the grayscale images using the ImShow function with appropriate titles and a grayscale flag\n","_, _ = ImShow(inverted_gray_images, inverted_gray_titles, title='RGB to Grayscale (Inverted)', grayscale=True)\n","# Display the inverted grayscale images using the ImShow function with appropriate titles and a grayscale flag"]},{"cell_type":"markdown","metadata":{"id":"Fq7FrFxYogHh"},"source":["***\n","<font color='Red'><b>Note:</b></font> Grayscale images only have one color channel (band).\n","***"]},{"cell_type":"markdown","metadata":{"id":"wr_AII3VogHi"},"source":["### RGB to HSV\n","\n","Converting an image from the RGB (Red, Green, Blue) color space to the HSV (Hue, Saturation, Value) color space is a common operation in image processing. The HSV color space separates the color information into three components: hue (the color itself), saturation (the intensity of the color), and value (the brightness). Here's how to perform the RGB to HSV conversion using OpenCV in Python:"]},{"cell_type":"markdown","metadata":{"id":"B7gnCHdCogHi"},"source":["<font color='Blue'><b>Example:</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"_tLWBvpGogHi"},"outputs":[],"source":["# Note that `Images` and `Names` were defined in the first example.\n","\n","# Convert Images from RGB to HSV color space\n","augmented_images_hsv = [cv2.cvtColor(image, cv2.COLOR_BGR2HSV) for image in Images]\n","\n","# Display the augmented images in HSV color space\n","_ = ImShow(augmented_images_hsv, Names, title='RGB to HSV')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}